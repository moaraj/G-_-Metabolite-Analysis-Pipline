---
title: "Correlation Plot"
author: "Moaraj_Hasan"
date: "24 April 2017"
output: 
  html_document: 
    fig_height: 7
    highlight: monochrome
    keep_md: yes
    number_sections: yes
    toc: yes
editor_options: 
  chunk_output_type: console
---
#Clear the environement
```{r}
#Clear Environment
rm(list = ls())
```

#Set Directory
```{r}
#If on the Alineware machine Set the Working Directory to this
if(Sys.info()[['sysname']] == "Windows"){
     setwd(dir = "D:/Dropbox/Aging BXD Study/D _ Metabolomics/G _ Metabolite-Analysis-Pipline/")
     }

```


#Setup
```{r Setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Change Language to english
Sys.setenv(LANG="en")

#Data import
library(readr)

#Data manipulation Packages
library(dplyr)
library(reshape2)
library(plyr)
library(tidyr)
library(tidyverse)

#Column Split 
library(stringr)

#For Plotting
library(ggplot2)
library(grid)
library(gridExtra)
library(ggthemes)
library(GGally)

#MAtrix Randomoization
library(picante)

# Convienience Function the Opposite of %in%
'%!in%' <- function(x,y)!('%in%'(x,y))

# Mod function
mod<-function(x,m)
  {
    t1<-floor(x/m)
    return(x-t1*m)
}

# Finding loaded Packages and Unloading Packages
search()
```

#Multiplot Function
```{r Multiple plot function}

# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots == 1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

#Grid Arrange With Legend on the Bottom
```{r grid_arrange_shared_legend}
grid_arrange_shared_legend <- function(...) {
    plots <- list(...)
    g <- ggplotGrob(plots[[1]] + theme(legend.position = "bottom"))$grobs
    legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
    lheight <- sum(legend$height)
    grid.arrange(
        do.call(arrangeGrob, lapply(plots, function(x)
            x + theme(legend.position = "none"))),
        legend,
        ncol = 1,
        heights = unit.c(unit(1, "npc") - lheight, lheight))
}
```

#Replicate Index function
Add indexes for replicaites using the mod function on the sample index
```{r Replicate Index,message=FALSE, warning=FALSE}
Replicate_index <- function(metab_data){

if(metab_data[1,"ET"] == metab_data[2,"ET"]){
metab_data <- merge(metab_data %>% 
mutate(Replicate  = paste("rep_", rep(c(1,2), times = dim(metab_data)[1]/2), sep = "")) %>% 
dplyr::select(Ion, Replicate), metab_data, by = "Ion")
#you need to have unqiue values in the bz mere
#can be done by selecting multiple columns

} else 
  
if( metab_data[1,"ET"] != metab_data[2,"ET"]) {
metab_data <- merge(metab_data %>% 
mutate(Replicate  = "rep_1") %>% dplyr::select(Ion, Replicate), metab_data, by = "Ion")  
}
  
return(metab_data)
}
```

```{r}
#Remove Alternative HMDB Names
    fix_HMDB_ids <- function(metab_data, factor_cols) {
	    name.vec <- colnames(metab_data)[(factor_cols + 1):ncol(metab_data)]
        name.vec <- as.character(lapply(name.vec, function(x) { substring(x, 1, 9) }) )
        colnames(metab_data)[(factor_cols + 1):ncol(metab_data)] <- name.vec
		return(metab_data)
    }
```

```{r}
#Average the Replicates Function

#Use this for Full Run 1
    Average_Replicates <- function(metabolite_data, factor_cols) {

	#Remove Useless Variables 
    useless.vars <- c("Conc", "Tissue.Weight", "Ion")

	#Remove Duplicated Columns
     metabolite_data <- metabolite_data[, !duplicated(colnames(metabolite_data))]
	
	#Take only the Major Extraction
    metabolite_data <- metabolite_data %>% filter(Extraction %in% c("NH2", "NH24", "NH24A"))

    #Make Variable Melt
	metabolite_data.melt <- melt(metabolite_data,
                            id = colnames(metabolite_data)[1:(factor_cols)] )

	metabolite_data.agg <- metabolite_data.melt %>%
                           group_by(Dataset, Extraction, ET, Strain, Diet, Sex, Age, Age.Cohort, variable) %>%
                           summarise_all(funs(mean), rep_man = "value")

	metabolite_data.agg <- metabolite_data.agg %>% select(-Replicate)
						   
    agg_cast <- dcast(metabolite_data.agg,
				Dataset + Extraction + ET + Strain + Diet + Sex + Age + Age.Cohort ~ variable,
				value.var = "value")

	return(agg_cast)
    }

```


#Metabolite Data Import
```{r}
metab_data0 <- read.delim(file = "3.csv_evan1.csv", sep = ",")
metab_data1 <- read.delim(file = "3.csv_moaraj1.csv", sep = ",")
metab_data3 <- read.delim(file = "3.csv_moaraj3.csv", sep = ",")
metab_data4 <- read.delim(file = "3.csv_moaraj4.csv", sep = ",")
metab_data5 <- read.delim(file = "3.csv_moaraj5.csv", sep = ",")

Metabolite_datasets <- list(Science = metab_data0,
							Opt_1 = metab_data1,
							Opt_3 = metab_data3,
							FullRun_1 = metab_data4,
							FullRun_2 = metab_data5)

rm(metab_data0, envir = as.environment(".GlobalEnv"))
rm(metab_data1, envir = as.environment(".GlobalEnv"))
rm(metab_data2, envir = as.environment(".GlobalEnv"))
rm(metab_data3, envir = as.environment(".GlobalEnv"))
rm(metab_data4, envir = as.environment(".GlobalEnv"))

Metabolite_dataset_names <- names(Metabolite_datasets)

Metabolite_datasets <- lapply(Metabolite_dataset_names, function(x){
			
	metab_df = Metabolite_datasets[[x]]
	Dataset <- as.character(rep(x,nrow(metab_df)))
	metab_df_fin <- cbind.data.frame(Dataset,metab_df)
	names(metab_df_fin)[2] <- "Ion"
	
	metab_df_fin <- Replicate_index(metab_df_fin) #Label Replicates
	metab_df_fin <- fix_HMDB_ids(metab_df_fin,11) # Replace HMDBids With Names
	metab_df_fin <- Average_Replicates(metab_df_fin,11) #Average Replicates

	metab_df_fin
	})

names(Metabolite_datasets) <- Metabolite_dataset_names
```

# Covnert HMDB to Other IDs
```{r}
HMDB_Dictionary <- read.csv(file="2.Metabolite.Name.Dict.csv")

HMDB_to_Name <- function(metabolite_data, factor_cols) {

    metab_names <- colnames(metabolite_data[(factor_cols + 1):ncol(metabolite_data)])

res <-  as.character( unlist (
	lapply(metab_names, function(name) {
	name_index <- grep(pattern = name, x = HMDB_Dictionary[, 'HMDB'], fixed = T)
	res <- HMDB_Dictionary[name_index, 'Name']
    })))

    new.colnames <- c(colnames(metabolite_data[1:(factor_cols)]),res)
    colnames(metabolite_data) <- new.colnames

    return(metabolite_data)

}

Metabolite_datasets_HMDB <- Metabolite_datasets #Save the Dataset with Molecule Name
Metabolite_datasets_MetabName <- lapply(Metabolite_dataset_names, # Save the dataset with the HMDB id
					   function(x){HMDB_to_Name(Metabolite_datasets[[x]],11)})


```



#Perform Data Normalization to the Total ion count
```{r}

metab_matrix_TIC_Norm <- function(metabolite_data,factor_cols ){
	
	metabolite_matrix <- as.data.frame(metabolite_data[(factor_cols + 1):ncol(metabolite_data)])
		
    #Normalize to TIC
    metab_means <- rowMeans(metabolite_matrix)
    metab_mean <- mean(metab_means)

    norm_vec <- lapply(metab_means, function(x) {metab_mean/x})
    norm_matrix <- diag(norm_vec)

    metabolite_matrix_norm <- as.data.frame(norm_matrix %*% as.matrix(metabolite_matrix))

	fin_metab_data <- cbind.data.frame(metabolite_data[1:factor_cols],metabolite_matrix_norm)
	
	fin_metab_data.melt <- melt(fin_metab_data, 
								id= ( colnames(fin_metab_data)[1:factor_cols]) )

	# This Function Returns the Normalized Dataframe and the Melted Normalized data frame in a list
	# Use the [['metab.df']] or [['metab.df.melt']] to see which one to access

	return( list( metab.df = as.data.frame(fin_metab_data),
				  metab.df.melt = as.data.frame(fin_metab_data.melt)) )
	}

```

```{r}
#Plotting Functions for the Normalized data before and After
{
	#Sample Some Metabolites to Plot for factor wise data
	metabolite_matrix_melt <- melt(metabolite_matrix[, c(seq(1, ncol(metabolite_matrix), 25))])
    colnames(metabolite_matrix_melt) <- c("Dataset","Metabolite", "Intensity")

    ggplot(data = metabolite_matrix_melt, aes(x = Intensity, colour = Metabolite, fill = Metabolite)) +
    geom_histogram(aes(y = ..density..), colour = "black", fill = "white") + # Histogram with density instead of count on y-axis
    geom_density(alpha = .2) + # Overlay with transparent density plot
    facet_wrap(~Metabolite, ncol = 3)

	ggplot(data = metabolite_matrix_melt, aes(x = log(Intensity, 2), colour = Metabolite, fill = Metabolite)) +
    geom_histogram(aes(y = ..density..), colour = "black", fill = "white") + # Histogram with density instead of count on y-axis
    geom_density(alpha = .2) + # Overlay with transparent density plot
    facet_wrap(~Metabolite, ncol = 3)

	#look at the Data Strain wise to see if ther eare some strain that are alwasys really low
    metabolite_matrix_strain <- cbind.data.frame(metabolite_matrix$Strain,
                                                 metabolite_matrix[(factor_cols + 1):ncol(metabolite_data)])
    metabolite_matrix_strain_melt <- melt(metabolite_matrix_strain[, c(seq(1, ncol(metabolite_matrix), 33))])
    colnames(metabolite_matrix_strain_melt) <- c("Strain", "Metabolite", "Intensity")

    ggplot(data = metabolite_matrix_strain_melt, aes(x = log(Intensity,2), colour = Strain, fill = Strain)) +
    geom_histogram(aes(y = ..density..), colour = "black", fill = "white") + # Histogram with density instead of count on y-axis
    geom_density(alpha = .1) #+ # Overlay with transparent density plot
    #facet_wrap(~Metabolite, ncol = 3)

	#Sample Some Metabolites to Plot Nomralized Matrix
    metabolite_matrix_norm_melt <- melt(metabolite_matrix_norm[, c(seq(1, ncol(metabolite_matrix_norm), 25))])
	colnames(metabolite_matrix_norm_melt) <- c("Metabolite", "Intensity")
	
	
	ggplot(data = metabolite_matrix_norm_melt, aes(x = log(Intensity, 2), colour = Metabolite, fill = Metabolite)) +
    geom_histogram(aes(y = ..density..) , colour = "black", fill = "white") + # Histogram with density instead of count on y-axis
    geom_density(alpha = .2) + # Overlay with transparent density plot
    facet_wrap(~ Metabolite, ncol=3)
}

```

# Remove Bad Metabolites
```{r}
remove.bad.metabs <- function(data) {

# This function removed non-polar metabolites that are not 
# Quatitatively extracted using the Polar extraction protocol
# It Takes the metabolite data and assumes
# only the metabolite columns start with PS. PE. etc.
# and removes all of those columns

data <- data %>% setNames(make.names(names(.), unique = TRUE)) %>% 
	filter(Diet %in% c("HF","CD")) %>%
	select(- dplyr::contains(":")) %>%
	
	select(-starts_with("DG")) %>%
	
	select(-starts_with("PE")) %>%
	select(-starts_with("PS")) %>%
	select(-starts_with("PI")) %>%
	select(-starts_with("PG")) %>%
	select(-starts_with("PIP")) %>%
	
	select(-starts_with("SM")) %>%

	select(-starts_with("TG")) %>%
	select(-starts_with("TIG"))

}

```

```{r}
#These are the data sets with bad metabolites removed
#the mouse intensities are normlized to the total ion counts

Metabolite_Just_Filtered <- lapply (Metabolite_datasets, function(x){remove.bad.metabs(x)} )


Normalized_then_Filtered <- lapply (Metabolite_datasets,
		function(x){ remove.bad.metabs(metab_matrix_TIC_Norm(x,8)[['metab.df']])} )
					
# Conversely we can try to predict what happens when we 
# first remove the bad metaboites and THEN we normalize, 
# To see what kind of bias we are introducing into the data

Filtered_then_Normalized <- lapply (Metabolite_datasets,
		function(x){ metab_matrix_TIC_Norm(remove.bad.metabs(x),8)[['metab.df']]} )

```

#Visualize what happens to Strain Aggregates across diets before and after the filter

```{r}
Plot_Filter_Difference <- function(DataSet,factor_cols){
	
	Condition_1.df <- Metabolite_datasets[[DataSet]]
	Condition_2.df <- Metabolite_Just_Filtered[[DataSet]]
	Condition_3.df <- Filtered_then_Normalized[[DataSet]]
	Condition_4.df <- Normalized_then_Filtered[[DataSet]]

	#Create a list with all the conditions you want to plot against eachothe 
	Conditions_List <- list(Original = Condition_1.df,
							Just_Filtered = Condition_2.df,
							Filt_then_Norm = Condition_3.df,
							Norm_then_Filt = Condition_4.df)
	
	# Create a vector of the names of all the items in the conditions list
	# These will be used as keys to access the different obejects
	
	iteration_name_vector <- names(Conditions_List)
	Conditions_List_Melt <- lapply(iteration_name_vector, function(x) {
							metab.df <- Conditions_List[[x]]
							metab.df.melt <- melt(metab.df, id=c( colnames( metab.df[1:factor_cols] )))
							metab.df.melt$Condition <- x
							metab.df.melt
							} )
	
	sum_mdata <- do.call("rbind", Conditions_List_Melt)
	sum_mdata$Meta <- paste(sum_mdata$Diet, sum_mdata$Condition, sep = "_")
	sum_mdata$Meta <- factor( sum_mdata$Meta,
		levels = c("CD_Original","CD_Just_Filtered","CD_Filt_then_Norm","CD_Norm_then_Filt",
					"HF_Original","HF_Just_Filtered","HF_Filt_then_Norm","HF Norm_then_Filt"))
	sum_mdata <- na.omit(sum_mdata)

	sum_mdata_agg <- sum_mdata %>% group_by(Strain,Meta) %>% 
						mutate_all(mean) %>% 
						select(Strain,Meta,value)
	sum_mdata_agg <- na.omit(sum_mdata_agg)
	
	sum_mdata_table <- dcast(sum_mdata_agg, Strain~Meta, mean)
	
	CD_Analysis_table <-	sum_mdata_table %>% 
							select(Strain,dplyr::starts_with("CD")) %>%
							mutate(AbsDiff = CD_Original - CD_Norm_then_Filt) %>%
							mutate(FoldChange = CD_Original / CD_Norm_then_Filt) %>%
							mutate(FoldChange.Log2 = log2(CD_Original / CD_Norm_then_Filt)) 
   
	#Returns the Sum data and the Aggregated Sum data by strain
return(list(sum_mdata,sum_mdata_agg))
}

```

The function below shows the Boxplots of the Original metabolite Averages comapred to the
metabolite averages when filtered and then normalized, and conversely
the metabolites averages when the meatbolites are normalized and then filtered after ward
```{r}
#Box plot of Normalized and Filter effects on data

DataConditioning_Comparison_Boxplot_1 <- function(dataset){	
ggplot(data = Plot_Filter_Difference(dataset,8)[[1]], aes(y=log(value,2), x=Diet, colour=Meta)) + 
ggtitle(paste("Comparison of the Effect of Normalization and Filtering on",dataset)) +
geom_boxplot() + facet_wrap(~ Strain)} 

DataConditioning_Comparison_Boxplot_1("Opt_1")
DataConditioning_Comparison_Boxplot_1("Opt_3")
DataConditioning_Comparison_Boxplot_1("Science")
DataConditioning_Comparison_Boxplot_1("FullRun_1")
DataConditioning_Comparison_Boxplot_1("FullRun_2")

```
From Visual insepction one can conclude that Normalizatio and Filtering order does
not produce very large changes on strain wise averages of metabolites
however simply the act of normalizing moves the strain averages quite a bit


```{r}

	ggplot(data = na.omit(sum_mdata_agg), aes(y=log(value,2), x=Meta, colour=Meta)) + 
		labs(	x = "Diet and Filter Status",
				y = "Log2 Tranformed Metablite Intensities a.u") +
		theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
		facet_wrap(~ Strain) + 
		ggtitle("Comparison of Diet Wise TIC before and after Filtering Bad Metabolites") +
		geom_boxplot()

```

# Generate Gene Network Inputs
```{r}

Generate.GeneNetwork.Inputs <- function(name,dataset) {

# Normalize the data and then filter the data metabolites
metabdata.norm.melt <-  remove.bad.metabs(
						metab_matrix_TIC_Norm(
						Metabolite_datasets[[dataset]],8)[['metab.df.melt']])

Diet.agg <- metabdata.norm.melt %>% group_by(Strain, Diet,variable) %>% mutate_all(mean)
Sex.agg  <- metabdata.norm.melt %>% group_by(Strain, Sex, variable) %>% mutate_all(mean)
Age.agg <- metabdata.norm.melt %>% group_by(Strain, Age.Cohort, variable) %>% mutate_all(mean)
Diet.Age.agg <- metabdata.norm.melt %>% group_by(Strain, Diet,Age.Cohort , variable) %>% mutate_all(mean)

GeneNetwork.HF.df <- Diet.agg %>% filter(Diet == "HF") %>% select(Strain,value)
GeneNetwork.HF <- dcast(GeneNetwork.HF.df, Strain ~ variable, function(x){ mean(log(x)) })
write.table(GeneNetwork.HF, file = paste(sep="",name,"GeneNetworkInput_HF.txt"), row.names = F, quote = F, sep = "\t")

GeneNetwork.CD.df <- Diet.agg %>% filter(Diet == "CD") %>% select(Strain, value)
GeneNetwork.CD <- dcast(GeneNetwork.CD.df, Strain ~ variable, function(x) { mean(log(x)) })
write.table(GeneNetwork.CD, file = paste(sep="",name,"GeneNetworkInput_CD.txt"), row.names = F, quote = F, sep = "\t")

GeneNetwork.Young.df <- Age.agg %>% filter(Age.Cohort %in% c(1,2)) %>% select(Strain, value)
GeneNetwork.Young <- dcast(GeneNetwork.Young.df, Strain ~ variable, function(x){ mean(log(x)) })
write.table(GeneNetwork.Young, file = paste(sep="",name,"GeneNetworkInput_Young.txt"), row.names = F, quote = F, sep = "\t")

GeneNetwork.Old.df <- Age.agg %>% filter(Age.Cohort %in% c(3, 4)) %>% select(Strain, value)
GeneNetwork.Old <- dcast(GeneNetwork.Old.df, Strain ~ variable, function(x){ mean(log(x)) })
write.table(GeneNetwork.Old, file = paste(sep="",name,"GeneNetworkInput_Old.txt"), row.names = F, quote = F, sep = "\t")

GeneNetwork.HF.Old.df <- Diet.Age.agg %>% filter(Diet == "HF") %>% filter(Age.Cohort %in% c(3, 4)) %>%
	select(Strain, value)
GeneNetwork.HF.Old <- dcast(GeneNetwork.HF.Old.df, Strain ~ variable, function(x) { mean(log(x)) })
write.table(GeneNetwork.HF.Old, file = paste(sep="",name,"GeneNetworkInput_HF_Old.txt"), row.names = F, quote = F, sep = "\t")

GeneNetwork.CD.Old.df <- Diet.Age.agg %>% filter(Diet == "CD") %>% filter(Age.Cohort %in% c(3, 4)) %>%
	select(Strain, value)
GeneNetwork.CD.Old <- dcast(GeneNetwork.CD.Old.df, Strain ~ variable, function(x) { mean(log(x)) })
write.table(GeneNetwork.CD.Old, file = paste(sep="",name,"GeneNetworkInput_CD_Old.txt"), row.names = F, quote = F, sep = "\t")

GeneNetwork.HF.Young.df <- Diet.Age.agg %>% filter(Age.Cohort %in% c(1, 2)) %>%
	filter(Age.Cohort %in% c(1, 2)) %>%
	select(Strain, value)
GeneNetwork.HF.Young <- dcast(GeneNetwork.HF.Young.df, Strain ~ variable, function(x) { mean(log(x)) })
write.table(GeneNetwork.HF.Young, file = paste(sep="",name,"GeneNetworkInput_HF_Young.txt"), row.names = F, quote = F, sep = "\t")

GeneNetwork.CD.Young.df <- Diet.Age.agg %>% filter(Age.Cohort %in% c(1, 2)) %>%
    filter(Age.Cohort %in% c(1, 2)) %>%
	select(Strain, value)
GeneNetwork.CD.Young <- dcast(GeneNetwork.CD.Young.df, Strain ~ variable, function(x) { mean(log(x)) })
write.table(GeneNetwork.CD.Young, file = paste(sep="",name,"GeneNetworkInput_CD_Young.txt"), row.names = F, quote = F, sep = "\t")

}

Generate.GeneNetwork.Inputs("FullRun_1","FullRun_1")
Generate.GeneNetwork.Inputs("FullRun_2","FullRun_2")

```

# Generate MetaboAnalyst Input
```{r}

Generate.MetaboAnalyst.Inputs <- function(dataset){
	# Normalize the data and then filter the data metabolites
	metabdata.norm  <-  remove.bad.metabs(
						metab_matrix_TIC_Norm(
						Metabolite_datasets_HMDB[[dataset]],8)[['metab.df.melt']])

	metabdata.Strain <-   metabdata.norm %>%
 						  select(Strain,ET,variable,value) %>%
						  dcast(ET + Strain  ~ variable)
	write.csv(metabdata.Strain,file = paste(sep="_",dataset,"MetabAnalystInput_Strain.csv"),row.names = F, quote = F)

	metabdata.Diet <-   metabdata.norm %>%
 						  select(Diet,ET,variable,value) %>%
						  dcast(ET + Diet  ~ variable)
	write.csv(metabdata.Strain,file = paste(sep="_",dataset,"MetabAnalystInput_Diet.csv"),row.names = F, quote = F)

	metabdata.Age.Cohort <-   metabdata.norm %>%
 						  select(Age.Cohort,ET,variable,value) %>%
						  dcast(ET + Age.Cohort  ~ variable)
	write.csv(metabdata.Strain,file = paste(sep="_",dataset,"MetabAnalystInput_Age.Cohort.csv"),row.names = F, quote = F)

	metabdata.Age <-   metabdata.norm %>%
 						  select(Age,ET,variable,value) %>%
						  dcast(ET + Age  ~ variable)
	write.csv(metabdata.Strain,file = paste(sep="_",dataset,"MetabAnalystInput_Age.csv"),row.names = F, quote = F)

	metabdata.Sex <-   metabdata.norm %>%
 						  select(Sex,ET,variable,value) %>%
						  dcast(ET + Sex  ~ variable)
	write.csv(metabdata.Strain,file = paste(sep="_",dataset,"MetabAnalystInput_Sex.csv"),row.names = F, quote = F)}

Generate.MetaboAnalyst.Inputs("FullRun_1")
Generate.MetaboAnalyst.Inputs("FullRun_2")

```


# Generate RQTL Input
```{r}
#' Source the R code from an knitr file, optionally skipping plots
#' @param file the knitr file to source
#' @param skip_plots whether to make plots. If TRUE (default) sets a null graphics device
#' @return This function is called for its side effects
#' @export

source_rmd = function(file, skip_plots = TRUE) {
  temp = tempfile(fileext=".R")
  knitr::purl(file, output=temp)

  if(skip_plots) {
    old_dev = getOption('device')
    options(device = function(...) {
      .Call("R_GD_nullDevice", PACKAGE = "grDevices")
    })
  }
  source(temp)
  if(skip_plots) {
    options(device = old_dev)
}}
```


Correlation Plot Between the 3rd Optimization and Current Study
Plot of well seperated Metabolite over Diet
```{r}

x <- filter(metab_data4, Replicate == "rep_1") %>% dplyr::select(HMDB02038)
y <- filter(metab_data4, Replicate == "rep_2") %>% dplyr::select(HMDB02038)

x <- filter(metab_data4, Diet == "HF") %>% dplyr::select(HMDB02038)
y <- filter(metab_data4, Diet == "CD") %>% dplyr::select(HMDB02038)

plot(cbind.data.frame(y[1:700,],x[1:700,]))
```


#Get the Plots for the replicates
```{r }
rep_corr_plots <- pairWiseCor(
          (filter(metab_data4, Replicate == "rep_1") %>% 
             dplyr::select(-one_of(factor_cols, "Age.Cohort"))),
          (filter(metab_data4, Replicate == "rep_2") %>% 
             dplyr::select(-one_of(factor_cols, "Age.Cohort")))
                             )

rep_corr_plots <- melt(rep_corr_plots)

pdf("7.Rep_Corr_Plot.pdf", paper ="usr")
ggplot(data = rep_corr_plots, aes(x = rep_corr_plots$value, fill = rep_corr_plots$variable)) + 
geom_histogram(binwidth = .005) + facet_wrap(~variable, scales = 'free_x', ncol = 2) + 
#theme_bw() + 
scale_fill_brewer(palette="Set1") + 
scale_y_continuous(name = "") +
scale_x_continuous(name = "Correlation Coefficient", limits = c(0.4,1.0)) 
dev.off()
```

#Overlapping Subsets Function
```{r}
Overlapping_Subsets <- function(metab_data_1, metab_data_2)  {
  
print("Selecing the metabolites Common in both datasets")
mdata_intercept <- intersect(names(metab_data_1),
                             names(metab_data_2))

metab_data_1 <- metab_data_1 %>%
     select(one_of(mdata_intercept))

metab_data_2 <- metab_data_2 %>%
     select(one_of(mdata_intercept))

print("Aggregating Mice by Diet and Strain Means")
strain_means_1 <- aggregate(metab_data_1,
                            by = list(metab_data_1$Strain), 
                            FUN = mean)

strain_means_2 <- aggregate(metab_data_2,
                            by = list(metab_data_2$Strain), 
                            FUN = mean)


print("Selecting the Mouse Strains common 
in both datasets after aggregation")

strain_intercept <- intersect(strain_means_1$Group.1,
                              strain_means_2$Group.1)

corr_data_1 <- strain_means_1 %>%
     filter(Group.1 %in% strain_intercept)

corr_data_2 <- strain_means_2 %>%
     filter(Group.1 %in% strain_intercept)

print("Determining Factor Columns")
factor_cols <- names(metab_data_1[1:11])

print("Removing Factor Columns for Correlation Function")
corr_data_1 <- corr_data_1 %>% select(-one_of(factor_cols))
corr_data_2 <- corr_data_2 %>% select(-one_of(factor_cols))

return(  list(X1 = corr_data_1[-1],
              X1.names = corr_data_1[1],
              X2 = corr_data_2[-1],
              X2.names = corr_data_2[1])  )
}
```


#Pairwaise Correlation Graph 
```{r}
pairWiseCor <- function(metab_data_1,metab_data_2){

  pairs.1 <- names(metab_data_1)
  pairs.2 <- names(metab_data_2)
  pairs.df <- cbind(pairs.1, pairs.2)
  
  df <- data.frame (Variable1 = rep(0,nrow(pairs.df)),
                    Variable2 = rep(0, nrow(pairs.df)),
                    AbsSpearCor = rep(0, nrow(pairs.df)),
                    SpearCor = rep(0, nrow(pairs.df)),
                    AbsPearCor = rep(0, nrow(pairs.df)),
                    PearCor = rep(0, nrow(pairs.df)),
                    AbsKenCor = rep(0, nrow(pairs.df)),
                    KenCor = rep(0, nrow(pairs.df))) 
  
  for(i in 1:nrow(pairs.df)){

  print(paste("Computing Correlation Between",
              pairs.1[i], "and" ,pairs.2[i]))
    
  print(paste(i,"Iterations of Total", nrow(pairs.df)))

    df[i,1] <- pairs.1[i]
    df[i,2] <- pairs.2[i]
    
    df[i,3] <- abs(cor(method = "spearman",cbind.data.frame(metab_data_1[,i],metab_data_2[,i])))[1,2]
    df[i,4] <- cor(method = "spearman",cbind.data.frame(metab_data_1[,i],metab_data_2[,i]))[1,2]

    df[i,5] <- abs(cor(method = "pearson",cbind.data.frame(metab_data_1[,i],metab_data_2[,i]))[1,2])
    df[i,6] <- cor(method = "pearson",cbind.data.frame(metab_data_1[,i],metab_data_2[,i]))[1,2]
    
    df[i,7] <- abs(cor(method = "kendall", cbind.data.frame(metab_data_1[,i],metab_data_2[,i]))[1,2])
    df[i,8] <- cor(method = "kendall",cbind.data.frame(metab_data_1[,i],metab_data_2[,i]))[1,2]
  
  }
  return(df)
}
```

#Overlap between the Science and the Full Run metabolites
```{r}
overlap_metabs <- Overlapping_Subsets(metabolite_data, metab_data4)

Science_FullRun <- pairWiseCor(overlap_metabs$X1,overlap_metabs$X2)

Science_FullRun_plot <- melt(Science_FullRun)
ggplot(data = Science_FullRun_plot, aes(x = Science_FullRun_plot$value, fill = Science_FullRun_plot$variable)) + 
geom_histogram(binwidth = .05) + facet_wrap(~variable, scales = 'free_x', ncol = 2) + 
scale_fill_brewer(palette="Set1") + 
scale_y_continuous(name = "") +
scale_x_continuous(name = "Correlation Coefficient") 
```

#Boot Strapping Function
```{r}
correlation_bootstrap <- function(data_1,data_2,randomize,nboot,boot.subsample) {

if(nboot > 1){
  res.df <- data.frame(Variable1 = 0,
                   Variable2 = 0,
                   variable  = 0,
                   value     = 0,
                   nboot     = 0,
                   random    = 0)

  res.df <- res.df[-1,]

  for (i in 1:nboot) {
    
    if(randomize == 1) {
  
    print("Performing Covaraince Determination on the Randomized Rows in Frist Data Set")
    
    data_1_matrix <- data.matrix(data_1)
    data_1_matrix <- remove_matrix_na(data_1_matrix)
    data_1_rand <- randomizeMatrix(data_1_matrix,null.model = "frequency",iterations = 1000)
    data_1_rand <- data.frame(data_1_rand)
    
    data_2_matrix <- data.matrix(data_2)
    data_2_matrix <- remove_matrix_na(data_2_matrix)
    data_2_rand <- randomizeMatrix(data_2_matrix,null.model = "frequency",iterations = 1000)
    data_2_rand <- data.frame(data_2_rand)
    
    } else if (randomize != 1) {data_1_rand <- data_1; data_2_rand <- data_2}
    
  parwise_correlations <- pairWiseCor(data_1_rand,data_2_rand)
  parwise_correlations_melt <- melt(parwise_correlations)
  iteration_vector <- c(rep(i, nrow(parwise_correlations_melt)))
  
  iteration_vector <- cbind(parwise_correlations_melt, iteration_vector)
  
  #Addeding Scrambled or Normal Data Column
  if(randomize == 1) {
  
  random_vector <- (rep("Scrambled Data", nrow(parwise_correlations_melt)))
  iteration_vector <- cbind(iteration_vector, random_vector)
  
  } else if (randomize != 1) {
  
  random_vector <- (rep("Normal Data", nrow(parwise_correlations_melt)))
  iteration_vector <- cbind(iteration_vector, random_vector)
  
  }
  
  colnames(iteration_vector) <- names(res.df)
  res.df <- rbind.data.frame(res.df, iteration_vector)
  
    }
  
return(res.df)

} else if  (nboot == 1) {res.df <- pairWiseCor(data_1,data_2)
                         res.df <- melt(res.df)
res.df <- res.df[-1,]
res.df <- na.omit(res.df)
return(res.df)

    }
  }
```

#For Debugging
```{r, eval=FALSE, include=FALSE}
data_1 <- metab_data0
data_2 <- metab_data4 

metab_data_1 <- metab_data0
metab_data_2 <- metab_data4 

i = 1
randomize = 1
nboot = 10
boot.subsample = 10
```

#Remove Debugging Variables from global Environment
```{r}
remove(data_1)
remove(data_2)

remove(metab_data_1)
remove(metab_data_2)

remove(i)
remove(randomize)
remove(nboot)
remove(boot.subsample)
```


#Overlap Between the Science and the Full Run Metabolites with HF
```{r}
Corr_Bootstrap_Master_Function <- function(metab_data_1,metab_data_2,
                                       randomize,nboot,boot.subsample) {

overlap_metabs <- Overlapping_Subsets(metab_data_1,metab_data_2)

data_1 <- overlap_metabs$X1
data_2 <- overlap_metabs$X2

res.df <- correlation_bootstrap(data_1,data_2, randomize, nboot, boot.subsample)

res.df$random <- factor(res.df$random)
res.df$variable <- factor(res.df$variable)

return(res.df)
}
```


```{r}
y1.10 <- Corr_Bootstrap_Master_Function(metab_data0, 
                                    metab_data4, 
                                    randomize = 0, 
                                    nboot = 10, 
                                    boot.subsample = 100)

y2.10 <- Corr_Bootstrap_Master_Function(metab_data0, 
                                    metab_data4, 
                                    randomize = 1, 
                                    nboot = 10, 
                                    boot.subsample = 100)

HF <- function(x) {filter(x, Diet == "HF")}
CD <- function(x) {filter(x, Diet == "CD")}

y1.10.HF <- Corr_Bootstrap_Master_Function(HF(metab_data0), 
                                       HF(metab_data4), 
                                       randomize = 0, nboot = 10, boot.subsample = 100)

y2.10.HF <- Corr_Bootstrap_Master_Function(HF(metab_data0), 
                                       HF(metab_data4), 
                                       randomize = 1, nboot = 10, boot.subsample = 100)

y1.10.CD <- Corr_Bootstrap_Master_Function(CD(metab_data0), 
                                       CD(metab_data4), 
                                       randomize = 0, 
                                       nboot = 10, boot.subsample = 100)

y2.10.CD <- Corr_Bootstrap_Master_Function(CD(metab_data0), 
                                       CD(metab_data4), 
                                       randomize = 1, nboot = 10, boot.subsample = 100)

```

Perform 100 Boot Strap Iterations

```{r}
y1.100 <- Corr_Bootstrap_Master_Function(metab_data0, 
                                         metab_data4, 
                                         randomize = 0,
                                         nboot =  100,
                                         boot.subsample =  100)

y2.100 <- Corr_Bootstrap_Master_Function(metab_data0,
                                         metab_data4,
                                         randomize = 1,
                                         nboot = 100,
                                         boot.subsample =  100)
```




```{r}


pdf(file = "8.Correlation_Science_Full_run.CD.pdf", paper = "legal")
p1 <- plotting_res3.df(rbind(y1.10,y2.10))
p2 <- plotting_res2.df(rbind(y1.10,y2.10))

dev.off()

pdf(file = "8.Correlation_Science_Full_run.CD.pdf", paper = "legal")
p3 <- plotting_res3.df(rbind(y1.10.CD,y2.10.CD))
p4 <- plotting_res2.df(rbind(y1.10.CD,y2.10.CD))

dev.off()

pdf(file = "8.Correlation_Science_Full_run.HF.pdf", paper = "legal")
p5 <- plotting_res3.df(rbind(y1.10.HF,y2.10.HF))
p6 <- plotting_res2.df(rbind(y1.10.HF,y2.10.HF))

dev.off()



```


#Plotting res.df
```{r}

plotting_res2.df <- function(x){
# Histogram overlaid with kernel density curve
p.2 <- ggplot(x, aes(x=value)) + 
    geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
                   binwidth=.025,
                   colour="black", fill="white") +
    geom_density(alpha=.2, fill="#FF6666")  + # Overlay with transparent density plot
    facet_wrap(~ random)
return(p.2)
}

plotting_res3.df <- function(y){
# Histogram overlaid with kernel density curve
p.3 <- ggplot(y, aes(x=value)) + 
    geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
                   binwidth=.025,
                   colour="black", fill="white") +
    geom_density(alpha=.2, fill="#FF6666") + # Overlay with transparent density plot
    facet_wrap(~ variable + random,ncol = 2,scales = "free")

return(p.3)
}

```


#Importing Gene Data
```{r}

gene_data_t <- read.csv(file = "../F _ Correlation Plots Genes/Heart_data.csv", 
                        sep = ";",header = TRUE)

strain.names <- colnames(gene_data_t)
strain.names[1] <- "Strain"
colnames(gene_data_t) <- strain.names

gene_data_t %>% mutate_if(is.factor, as.character) -> gene_data_t
gene.names <- gene_data_t$Strain

#Transpose just the number in the data frame
gene_data <- as.data.frame(t(gene_data_t[2:ncol(gene_data_t)]))

#Add strains to column 1
gene_data <- cbind.data.frame(strain.names[-1],gene_data)

#make the genenames the columns
colnames(gene_data) <- c("Strain", gene.names)


gene_data <- gene_data %>% separate(Strain, c("Strain", "Diet"),"_")



gene_boot <- Succinct_Plotting_Function(filter(gene_data, Diet == "Chow"),
                                        filter(gene_data, Diet == "HiFat"),
                                        randomize = 0, nboot = 3, boot.subsample = 10000)

gene_boot_scrambled <- Succinct_Plotting_Function(filter(gene_data, Diet == "Chow"),
                                        filter(gene_data, Diet == "HiFat"),
                                        randomize = 1, nboot = 3, boot.subsample = 10000)

gene_plot <- plotting_res3.df(rbind(gene_boot,gene_boot_scrambled))


```

```{r}
Emperical_FDR <- function(boot,scrambled_boot){
  FDR.df <- cbind.data.frame(gene_boot[1],
                             gene_boot$variable,
                             gene_boot$value - gene_boot_scrambled$value)
  colnames(FDR.df) <- c("Variable", "Correlation.Coefficient", "FDR")

  return(FDR.df)  
}

FDR.df <- Emperical_FDR(gene_boot, gene_boot_scrambled)
plotting_res4.df(FDR.df)

```




```{r}
# Histogram overlaid with kernel density curve

coeff.filt <- function(x,i){
  coeffs <- as.character(unique(x$variable))
  n <- coeffs[i]
  x <- filter(x, variable == n)
  return(x)
  }


FDR.data <- function(data1,data2,i){

data1 <- coeff.filt(data1,i)
data2 <- coeff.filt(data2,i)

data1 <- data1$value
data2 <- data2$value

x = density(data1, from= range(c(data1, data2))[1], 
                 to=range(c(data1, data2))[2])$x

y1 = abs(        density(data1, from= range(c(data1, data2))[1], 
                 to=range(c(data1, data2))[2] )$y - (density(data1, from= range(c(data1, data2))[1], 
                 to=range(c(data1, data2))[2] )$y - density(data2,  
                 from= range(c(data1, data2))[1], 
                 to=range(c(data1, data2))[2])$y)         
        )

y2 = abs(        density(data2, 
                         from= range(c(data1, data2))[1],
                         to=range(c(data1, data2))[2])$y - 
                   (density(data1, from= range(c(data1, data2))[1], 
                            to=range(c(data1, data2))[2] )$y - 
                      density(data2,from= range(c(data1, data2))[1],
                              to=range(c(data1, data2))[2])$y)         
        )

y3 = abs((density(data1, from= range(c(data1, data2))[1], 
                 to=range(c(data1, data2))[2] )$y - density(data2,  
                 from= range(c(data1, data2))[1], 
                 to=range(c(data1, data2))[2])$y))

df <- cbind.data.frame(x,y1,y2,y3)

}

corr.df <- rbind.data.frame( FDR.data(gene_boot,gene_boot_scrambled,1),
                        #FDR.data(gene_boot,gene_boot_scrambled,2),
                        FDR.data(gene_boot,gene_boot_scrambled,3),
                        #FDR.data(gene_boot,gene_boot_scrambled,4),
                        FDR.data(gene_boot,gene_boot_scrambled,5)
                        #FDR.data(gene_boot,gene_boot_scrambled,6)
                      )

corr.df$corr <-gsub(df$corr,pattern = 1,replacement = "Pearson Correlation")
corr.df$corr <-gsub(df$corr,pattern = 3,replacement = "Spearman Correlation")
corr.df$corr <-gsub(df$corr,pattern = 5,replacement = "Kendall Correlation")

colnames(corr.df)
ggplot(data = corr.df, aes(x = x, y = y3, colour = factor(corr))) + 
geom_point() + geom_line() +
scale_x_continuous(limits = c(0,1)) + theme_grey() + 
xlab("Correlation Coefficient") +
ylab("Difference in Null and Signal Densities") +
ggtitle("Emperical False Discovery Rate of Genetic Data", subtitle = NULL) +
theme(axis.title.y = element_text(size = 14),axis.title.x = element_text(size = 14)) +
  
geom_hline(aes(yintercept = 0.1), colour = "black", size = 1, linetype = "dashed")  + 
geom_text(aes(0.1,.1,label = "10% Cut off", vjust = -0.3), color = "black", size = 6) + 
  
geom_hline(aes(yintercept = 0.5), colour = "black", size = 1, linetype = "dashed")  + 
geom_text(aes(0.1,.5,label = "50% Cut off", vjust = -0.3), color = "black", size = 6) + 
  
theme(legend.position = c(0.75, 0.5),
      legend.background = element_rect(fill="lightgrey",
      size=0.5 , linetype="solid", colour ="black")) +
scale_color_manual(name = "Correlation Coefficients",
                   labels = c("Pearson Correlation", 
                              "Spearman Correlation",
                              "Kendall Correlation"), values = c("blue", "red","green")) 



```

#Forest Method



#Multi AOV Script
```{r}

AOV_Script <- function(metab_data){
  
  #Set up variables for the aov analysis
  counts <- as.matrix(log(metab_data))
  colnames(counts) <- "counts"

#  factor.columns <- metab_data[1:factor_cols]
#  metabmatrix <- cbind.data.frame(factor.columns,counts)
    
  fit2 <- aov(formula = as.formula("counts ~ Diet + Sex + Age.Cohort + Strain"), 
              data = metab_data5.names)
  
  return((summary(fit2)))
}

Multi_GLM <- lapply(metab_data5.names[9:ncol(metab_data5.names)], AOV_Script)

AOV_Coeffs <- sapply(Multi_GLM, function(x){ -log (as.numeric( x[[1]][[5]][1:4] ) ) }) 
AOV_Coeffs <- cbind.data.frame(c("Diet","Sex","Age.Cohort","Strain"),AOV_Coeffs)
colnames(AOV_Coeffs)[1] <- "AOV_Coeff"

AOV_Coeffs <- melt(AOV_Coeffs)

```

```{r}
nfactor.cols = 11
metab_data <- metab_data1
inputs <- 12:20
```

```{r}
remove(nfactor.cols)
remove(metab_data)
remove(inputs)
```


```{r}

run.aov.par <- function(ncores,nfactor.cols,metab_data){

require(foreach)
require(doParallel)
require(parallel)

if(missing(ncores)){
  print("Cores Not Specified, Using All Cores")
numCores <- detectCores()
cl <- makeCluster(numCores - 1)
registerDoParallel(cl)
} else {
  cl <- makeCluster(ncores)
  registerDoParallel(cl)
}


# The function I was to run in parrallel
  # Needs to be ititlized in the new R environment
  
clusterExport(cl=cl, 
              list("metab_data"),
              envir=environment())

AOV_Script <- function(metab_data,metab){
  
  #Set up variables for the aov analysis
  counts <- as.matrix(log(metab_data[metab]))
  colnames(counts) <- "counts"
  factor.columns <- metab_data[1:11]
  metabmatrix <- cbind.data.frame(factor.columns,counts)
  
  fit <- aov(formula = as.formula("counts ~ Diet + Replicate + Sex + Age.Cohort + Strain"), 
             data = metab_data)
  
  fit2 <- glm(formula = as.formula("counts ~ Diet + Replicate + Sex + Age.Cohort + Strain"), 
              data = metab_data)
  
  
  return(fit)
}
  
inputs <- (nfactor.cols + 1):ncol(metab_data)
processInput <- function(i) {
  AOV_Script(metab_data,i)
}

results <- foreach(i=inputs) %dopar% {
  processInput(i)
}

return(results)

stopCluster(cl)
}

mres.data1 <- run.aov.par(ncores = 7,nfactor.cols = 11,metab_data1)

```

```{r}

drop.useless.factors <- function(DF){DF[, sapply(DF, function(col) length(unique(col))) > 1]}
metab.4.filt <- drop.useless.factors(metab_data4)

metab.4.full.factorized <- as.data.frame(lapply(metab_data4[1:11],as.factor))
metab.4.full.factorized <- cbind.data.frame(metab.4.full.factorized,
                                            metab_data4[12:ncol(metab_data4)])

```

```{r}
#Diet based filtering
metab.4.filt.diet <- cbind.data.frame(metab.4.filt[7],metab.4.filt[11:ncol(metab.4.filt)])
metab.4.filt.diet.bin <- metab.4.filt.diet
metab.4.filt.diet.bin[1] <- gsub(metab.4.filt.diet[1], pattern = "CD",replacement = 0)
metab.4.filt.diet.bin[1] <- gsub(metab.4.filt.diet[1], pattern = "HF",replacement = 1)

```

```{r}
library(Amelia)
missmap(metab.4.filt.diet.bin, main = "Missing values vs observed")


fit3 <- glm(formula = as.formula("Strain ~ ."), 
            data = metab4.data[-c(1:6, 8:12)],
            family = binomial(link = "logit"))

summary(fit3)

```



#Exploratory Comparisions


#Upset Analysis
Which Metabolites are found in Science paper but not in the Current Study
Which metabolites show the highest fold change in the HF and CD

#Diet Fold CHange Function
```{r}
DietFoldChange <- function(data,nfactorcols) {

  #nfactorcols <- 10
  #data <- metab_data0.names
 

data.CD <- data %>% filter(Diet == "CD")
data.CD.mean <- colMeans(data.CD[(nfactorcols + 1) :ncol(data.CD)])
data.CD.var <- as.numeric(lapply(data.CD[(nfactorcols + 1) :ncol(data.CD)], sd))
n.CD.samples <- nrow(data.CD)/2

data.HF <- data %>% filter(Diet == "HF")
data.HF.mean <- colMeans(data.HF[(nfactorcols + 1):ncol(data.HF)])
data.HF.var <- as.numeric(lapply(data.HF[(nfactorcols + 1) :ncol(data.CD)], sd))
n.HF.samples <- nrow(data.HF)/2


Diet.DF <- as.data.frame(t(rbind(data.HF.mean, data.HF.var,
                                 data.CD.mean, data.CD.var)))

colnames(Diet.DF) <- c("HF.mean","HF.var","CD.mean","CD.var")

Diet.DF <- tibble::rownames_to_column(Diet.DF,var = "Metabolite")

Diet.DF[is.na(Diet.DF)] <- 0

Diet.DF <- Diet.DF %>% mutate(AbsDiff = HF.mean - CD.mean) %>%
                       mutate(FoldChange = HF.mean/CD.mean) %>% 
                       mutate(Std.FoldChange = (HF.mean/HF.var) / (CD.mean/CD.var)) %>%
                       mutate(FoldChange.Log2 = log2(HF.mean/ CD.mean)) %>%
                       mutate(T.Stat = (HF.mean - CD.mean) / 
                       sqrt(HF.var^2/n.HF.samples + CD.var^2/n.CD.samples)) %>%
                       mutate(T.Test = pchisq(abs(T.Stat),1,lower.tail = FALSE)) %>%
                       mutate(Bonferroni.P = T.Test * n.HF.samples) %>%
                       arrange(FoldChange.Log2)
return(Diet.DF)
}
```

Generate data from the Diet fold function and plot
```{r}
    Diet.DF.0 <- DietFoldChange(metab_data0.names, 10)
    Diet.DF.1 <- DietFoldChange(metab_data1.names, 10)
    Diet.DF.3 <- DietFoldChange(metab_data3.names, 10)
    Diet.DF.4 <- DietFoldChange(metab_data4.names, 13)
    Diet.DF.5 <- DietFoldChange(metab_data5.names, 12)
	
    plot(Diet.DF.0$HF.mean, Diet.DF.0$CD.mean, log = "xy")

    model.Diet = lm(data = Diet.DF.0, formula = HF.mean ~ CD.mean)
    summary(model.Diet)
#    plot(model.Diet)
```


#Age Cohort fold Change

```{r}

AgeFoldChange <- function(data,nfactorcols) {

  #nfactorcols <- 12
  #data <- metab_data5.names

    data$Age <- as.numeric(data$Age)
	
    data.Young <- data %>% filter(Age < quantile(data$Age, c(0.5), na.rm = TRUE))
	data.Young.mean <- colMeans(data.Young[(nfactorcols + 1):ncol(data.Young)])
	data.Young.var <- as.numeric(lapply(data.Young[(nfactorcols + 1):ncol(data.Young)], sd))
	n.Young.samples <- nrow(data.Young) / 2

    data.Old <- data %>% filter(Age > quantile(data$Age, c(0.5), na.rm = TRUE))
	data.Old.mean <- colMeans(data.Old[(nfactorcols + 1):ncol(data.Old)])
	data.Old.var <- as.numeric(lapply(data.Old[(nfactorcols + 1):ncol(data.Old)], sd))
    n.Old.samples <- nrow(data.Old) / 2


Age.DF <- as.data.frame(t(rbind(data.Young.mean, data.Young.var,
                                 data.Old.mean, data.Old.var)))

colnames(Age.DF) <- c("Young.mean","Young.var","Old.mean","Old.var")

Age.DF <- tibble::rownames_to_column(Age.DF,var = "Metabolite")


Age.DF[is.na(Age.DF)] <- 0

    Age.DF <- Age.DF %>% mutate(AbsDiff = Young.mean - Old.mean) %>%
                       mutate(FoldChange = Young.mean / Old.mean) %>%
                       mutate(FoldChange.Log2 = log2(Young.mean / Old.mean)) %>%
                       mutate(T.Stat = (Young.mean - Old.mean) /
                       sqrt(Young.var ^ 2 / n.Young.samples + Old.var ^ 2 / n.Old.samples)) %>%
                       mutate(T.Test = pchisq(abs(T.Stat), 1, lower.tail = FALSE)) %>%
                       mutate(Bonferroni.P = T.Test * n.Young.samples) %>%
                       arrange(FoldChange.Log2)
    
    #Age.res <- lapply(Age.DF, function(x) x[is.infinite(x)])

	#metabolites_list_names <- as.data.frame( Age.DF$Metabolite)
    #Age.res$Metabolite <- metabolites_list_names

	#Age.DF.final <- do.call(cbind.data.frame, Age.res)

    Age.Min <- min(Age.DF$FoldChange)
    Age.Max <- max(Age.DF$FoldChange)

    Age.DF$Norm.FoldChange <- (Age.DF$FoldChange - Age.Min) / (Age.Max - Age.Min)



return(Age.DF)

}

# Generate Age Related Metabolite Diet

    Age.DF.0 <- AgeFoldChange(metab_data0.names, 10)
    Age.DF.1 <- AgeFoldChange(metab_data1.names, 10)
    Age.DF.3 <- AgeFoldChange(metab_data3.names, 11)
    Age.DF.4 <- AgeFoldChange(metab_data4.names, 13)
    Age.DF.5 <- AgeFoldChange(metab_data5.names, 12)

```




#Which of the Top hits in the first study corroborate with the hits in my study
Write a funtion that filters out the data that meets a Z score or T test Cutt off
```{r}

Hit.Filter <- function(data, critical.value) {
  #data = Diet.DF.0
  #critical.value = 1
  data1 <- filter(data, T.Stat < -critical.value)
  data2 <- filter(data, T.Stat > critical.value)
  data <- rbind.data.frame( data1, data2 )
  return((data$Metabolite))
}

```



```{r]

library(UpSetR)
Metabolite_Venn_Data <- list(Science_Paper = (Diet.DF.0$Metabolite),
                             Opt_Run_1 = (Diet.DF.1$Metabolite),
                             Opt_Run_3 = (Diet.DF.3$Metabolite),
                             Full_Run_1 = (Diet.DF.4$Metabolite),
                             Full_Run_2 = (Diet.DF.5$Metabolite))

Metabolite_Venn_Data_Full_Runs <- list(Science_Paper = (Diet.DF.0$Metabolite),
                             Full_Run_1 = (Diet.DF.4$Metabolite),
                             Full_Run_2 = (Diet.DF.5$Metabolite))

Metabolite_Hits_Venn_Data <- list(Science_Paper = Hit.Filter(Diet.DF.0,2) ,
                             Opt_Run_1 = Hit.Filter(Diet.DF.1,2) ,
                             #Opt_Run_3 = Hit.Filter(Diet.DF.3,2) ,
                             Full_Run_1 = Hit.Filter(Diet.DF.4, 2),
                             Full_Run_2 = (Diet.DF.5$Metabolite)
							 )


upset(fromList(Metabolite_Venn_Data))
upset(fromList(Metabolite_Hits_Venn_Data))
upset(fromList(Metabolite_Venn_Data_Full_Runs))

upset(fromList(Metabolite_Venn_Data), 
      queries = list(list(query = intersects, 
                          params = list("Science_Paper", "Full_Run_1"), 
                          color = "orange", active = T),
                     list(query = intersects,
                          params = list("Science_Paper", "Full_Run_1", 
                                        "Opt_Run_1", "Opt_Run_3"),
                          color = "red", active = T)))

upset(fromList(Metabolite_Hits_Venn_Data), 
      queries = list(list(query = intersects, 
                          params = list("Science_Paper", "Full_Run_1"), 
                          color = "orange", active = T),
                     list(query = intersects,
                          params = list("Science_Paper", "Full_Run_1", 
                                        "Opt_Run_1", "Opt_Run_3"),
                          color = "red", active = T)))


Diet.DF.0 <- do.call(data.frame,lapply(Diet.DF.0, function(x) replace(x, is.infinite(10),NA)))
plot(Diet.DF.0$FoldChange.Log2, -log(Diet.DF.0$T.Test), ylim = c(0,15), xlim = c(-4,2.5))

```


#Write a function that generates a Volcaneo Plot from the Tabulated Data
```{r}
volcano.plot <- function(data,critical.value){
  ggplot(data = data, 
  aes(x = FoldChange.Log2, y = -log(T.Test), color = -log(T.Test) > critical.value)) + geom_point() +
    scale_y_continuous() + scale_x_continuous() +
	geom_vline(xintercept = 0) + geom_hline(yintercept = 0) +
    ggrepel::geom_label_repel(aes(label = ifelse(-log(T.Test) > critical.value, as.character(Metabolite), ''),
    fontface = 'bold', color = 'white')) +
	theme_minimal(base_size = 16)
}

volcano.plot2 <- function(data, critical.value) {
        ggplot(data = data,
        aes(x = FoldChange.Log2, y = -log(T.Test), color = -log(T.Test) > critical.value)) +
		geom_point() +
        scale_y_continuous() + scale_x_continuous() +
        geom_vline(xintercept = 0) + geom_hline(yintercept = 0) +
        theme_minimal(base_size = 16)
    }


```

#MAke Diet Volcano Plots
```{r}
pdf(file = "volcano_diet.pdf", width = 10, height = 7.5)
#volcano.plot(Diet.DF.0,3)
#volcano.plot(Diet.DF.1,3)
#volcano.plot(Diet.DF.3,3)
#volcano.plot(Diet.DF.4,3)
volcano.plot(Diet.DF.5, 3)
dev.off()

pdf(file = "volcano_diet_nolab.pdf", width = 10, height = 7.5)
volcano.plot2(Diet.DF.5, 3)
dev.off()

```


# Make Age Volcano Plots
```{r}
pdf(file = "volcano_age.pdf",width=10,height=7.5)
#volcano.plot(Age.DF.0,20)						
#volcano.plot(Age.DF.1,4)
#volcano.plot(Age.DF.3,4)
#volcano.plot(Age.DF.4, 3)
volcano.plot(Age.DF.5, 3)

dev.off()

pdf(file = "volcano_age_nolab.pdf", width = 10, height = 7.5)
volcano.plot2(Age.DF.5, 3)
dev.off()
```



#Exploratory PCA and Factor anaylsis

Generate Data for PCA analysis
```{r}

metab4.data <- metab_data5.names

PCA_dataset <- log(data.matrix(metab4.data[14:ncol(metab4.data)]))

library(ggfortify)

autoplot(kmeans(PCA_dataset, 2), data = metab4.data)
autoplot(kmeans(PCA_dataset, 2), data = metab4.data, label = TRUE, label.size = 3)

library(cluster)


autoplot(pam(PCA_dataset, 2), frame = TRUE, frame.type = 'norm')
autoplot(prcomp(PCA_dataset, scale = T), frame = TRUE, frame.type = 'norm',
                     loadings = TRUE, loadings.colour = 'blue',
                     loadings.label = TRUE, loadings.label.size = 3)

autoplot(fanny(PCA_dataset, 2), frame = TRUE)

autoplot(pam(PCA_dataset.log, 2), frame = TRUE, frame.type = 'norm')
autoplot(fanny(PCA_dataset.log, 2), frame = TRUE)


    library(reshape2)
    library(ggplot2)

    pca <- prcomp(PCA_dataset, scale = T)
    pca_dim_data <- cbind.data.frame(names(pca$rotation[, 1]), (pca$rotation[, 1:9]))
    pca_dim_data <- pca_dim_data[1:40,]

    melted <- melt(pca_dim_data)
	colnames(melted) <- c("metab","PC","value")

    barplot <- ggplot(data = melted) +
    geom_bar(aes(x = metab, y = value, fill = metab), stat = "identity") +
    facet_wrap(~PC)
    barplot + theme(axis.text.x = element_text(angle = 90, hjust = 1))

    scores <- data.frame(sample.groups, pca$x[, 1:3])
    pc1.2 <- qplot(x = PC1, y = PC2, data = scores, colour = factor(sample.groups)) +
    theme(legend.position = "none")
    pc1.3 <- qplot(x = PC1, y = PC3, data = scores, colour = factor(sample.groups)) +
    theme(legend.position = "none")
    pc2.3 <- qplot(x = PC2, y = PC3, data = scores, colour = factor(sample.groups)) +
    theme(legend.position = "none")

library(lfda)

# Local Fisher Discriminant Analysis (LFDA)
model <- lfda(x = PCA_dataset, y = metab4.data[,3], 4, metric="plain")
autoplot(model, data = metab4.data, frame = TRUE, frame.colour = 'Diet')
autoplot(model, data = metab4.data, frame = TRUE, frame.colour = 'Sex')
autoplot(model, data = metab4.data, frame = TRUE, frame.colour = 'Strain')
autoplot(model, data = metab4.data, frame = TRUE, frame.colour = 'Age.Cohort')
autoplot(model, data = metab4.data, frame = TRUE, frame.colour = 'Replicate')


# Kernel Local Fisher Discriminant Analysis (KLFDA)
model2 <- klfda(kmatrixGauss(PCA_dataset), metab4.data[,3], 4, metric="plain")
autoplot(model2, data = metab4.data, frame = TRUE, frame.colour = 'Diet')
autoplot(model2, data = metab4.data, frame = TRUE, frame.colour = 'Sex')
autoplot(model2, data = metab4.data, frame = TRUE, frame.colour = 'Strain')
autoplot(model2, data = metab4.data, frame = TRUE, frame.colour = 'Age.Cohort')
autoplot(model2, data = metab4.data, frame = TRUE, frame.colour = 'Replicate')

# Semi-supervised Local Fisher Discriminant Analysis (SELF)
model3 <- self(PCA_dataset, metab4.data[,3], beta = 0.2, r = 5, metric="plain")
autoplot(model3, data = metab4.data, frame = TRUE, frame.colour = 'Diet')


```


Plotting Classical (Metric) Multidimensional Scaling
```{r}

plot(dist(PCA_dataset))

autoplot(cmdscale(dist(PCA_dataset), eig = TRUE), label = TRUE, label.size = 3)

library(MASS)
autoplot(sammon(dist(PCA_dataset)), shape = FALSE, label.colour = 'blue', label.size = 3)
```

http://rpubs.com/sinhrks/plot_pca

```{r}
    
PCA_res <- prcomp(PCA_dataset,scale. = TRUE)
PCA_dataset.no.out <- lapply(PCA_dataset, function(x) {x[!x %in% boxplot.stats(x)$out]})
#pdf(file = "PCA_Plots.pdf", width = 16,height = 9)
    autoplot(prcomp(PCA_dataset, scale =T ), data = metab4.data, colour = 'Strain')
    autoplot(prcomp(PCA_dataset, scale = T), data = metab4.data, colour = 'ET') +
         theme(legend.position="none")
    autoplot(prcomp(PCA_dataset, scale = T), data = metab4.data colour = 'replicate')
    autoplot(prcomp(PCA_dataset, scale = T), data = metab4.data, colour = 'Sex')
    autoplot(prcomp(PCA_dataset, scale = T), data = metab4.data, colour = 'Diet')
    autoplot(prcomp(PCA_dataset, scale = T), data = metab4.data, colour = 'Age.Cohort')
    autoplot(prcomp(PCA_dataset, scale = T), data = metab4.data, colour = 'Extraction')

#Passing loadings = TRUE draws eigenvectors.
  autoplot(prcomp(PCA_dataset), 
           data = data, 
           colour = 'Diet', 
           loadings = TRUE, 
           loadings.label = TRUE, 
           loadings.colour = "blue",
           loadings.label.size = 1)

```


```{r}
    ## calling TSNE
    library(Rtsne)
    ## Curating the database for analysis with both t-SNE and PCA

	Labels <- train$label
    train$label <- as.factor(train$label)
    ## for plotting
    colors = rainbow(length(unique(train$label)))
    names(colors) = unique(train$label)

    ## Executing the algorithm on curated data
    tsne <- Rtsne(train[, -1], dims = 2, perplexity = 30, verbose = TRUE, max_iter = 500)
    

    ## Plotting
    plot(tsne$Y, t = 'n', main = "tsne")
    text(tsne$Y, labels = train$label, col = colors[train$label])

```


```{r}
# Pricipal Components Analysis
# entering raw data and extracting PCs 
# from the correlation matrix 

fit <- princomp(PCA_dataset, cor = TRUE, scale=TRUE)
summary(fit) # print variance accounted for 
loadings(fit) # pc loadings 
plot(fit, type="bar") # scree plot 
fit$scores # the principal components
biplot(fit,pc.biplot = 1, lenght = 20, width = 20)
```


Exploratory Factor Analysis
The factanal( ) function produces maximum likelihood factor analysis.
```{r}
# Maximum Likelihood Factor Analysis
# entering raw data and extracting 3 factors, 
# with varimax rotation 
fit <- factanal(PCA_dataset, factors = 10, rotation="varimax")

print(fit, digits=2, cutoff=.3, sort=TRUE)
# plot factor 1 by factor 2 
load <- fit$loadings[,1:2] 
plot(load,type="n") # set up plot 
text(load,labels=names(PCA_dataset),cex=.7) # add variable names
```


Determining the Number of Factors to Extract
A crucial decision in exploratory factor analysis is how many factors to extract. 
The nFactors package offer a suite of functions to aid in this decision. 
Of course, any factor solution must be interpretable to be useful.
```{r}
# Determine Number of Factors to Extract
library(nFactors)
ev <- eigen(cor(PCA_dataset)) # get eigenvalues
ap <- parallel(subject=nrow(PCA_dataset),
               var=ncol(PCA_dataset),
               rep=10,cent=.05)

nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)

plotnScree(nS)

plot(c(1:354),nS$Analysis$Eigenvalues, 
     xlim = c(0,50), type = "b")
lines(c(1:354),nS$Analysis$Cumu, col = "red")
lines(c(1:354),nS$Analysis$Par.Analysis, col = "blue")
lines(c(1:354),nS$Analysis$Pred.eig)

```

From the nFactors Analysis the optimal number of groups 
for the metabolic data seems to be around 31
```{r}
d.factanal <- factanal(PCA_dataset, factors = 31, scores = 'regression')
autoplot(d.factanal, data = PCA_dataset, colour = 'Diet')

autoplot(d.factanal, label = TRUE, label.size = 3,
         loadings = TRUE, loadings.label = TRUE, loadings.label.size  = 3)
```


The FactoMineR package offers a large number of additional functions for exploratory factor analysis. This includes the use of both quantitative and qualitative variables, 
as well as the inclusion of supplimentary variables and observations. 
```{r}
# PCA Variable Factor Map 
library(FactoMineR)
# graphs generated automatically
result <- PCA(PCA_dataset, graph = TRUE, scale.unit = TRUE)

result <- PCA(PCA_dataset, 
              graph = TRUE,
              scale.unit = TRUE)

m <- cbind.data.frame(result$var[1])

plot(result$eig$eigenvalue, ylim = c(0,100), xlim = c(0,40), type = "b")
lines(result$eig$`percentage of variance`, type = "b", col = "red")
lines(result$eig$`cumulative percentage of variance`, type = "b", col = 'blue')
View(m)
```


Generate Data that is more Amenable to Cluster Analysis Tooks in ggfortify
```{r}
Cluster_dataset <- data.matrix(data[14:30], rownames.force = NA)
data_replicate <- data[1:365]
```


{ggfortify} supports cluster::clara, cluster::fanny, cluster::pam classes. Because these instances should contains original data in its property, there is no need to pass original data explicitly.
```{r}
library(cluster)
Cluster_dataset <- data.matrix(data[14:365], rownames.force = NA)
colnames(Cluster_dataset) <- gsub(colnames(Cluster_dataset),pattern = " ", replacement = ".")
autoplot(clara(Cluster_dataset, 368,correct.d = TRUE))
```


#Hirarchial Clustering to Determine if Biological Replicates Cluster Together
```{r}
duplicates_metab_data <- filter(metab_data, Extraction == "NH24_D") %>% 
                         filter(Extraction != "Blank") %>%
                         filter(Extraction != "Empty") %>%
                         filter(Extraction != "Unknown") %>%
                         filter(Mouse != "Blank") %>%
                         filter(Mouse != "Empty") %>%
                         filter(Mouse != "Unknown")

rownames(duplicates_metab_data) <- paste(duplicates_metab_data$Index,
                                         "Mouse:", duplicates_metab_data$Mouse, 
                                         "Strain:", duplicates_metab_data$Strain,
                                         "Replicate:",duplicates_metab_data$replicate,
                                         duplicates_metab_data$Extraction)

mouse_duplicates_ETs <- unique(duplicates_metab_data$Mouse)
replicates_metab_data <- filter(metab_data, Mouse %in% mouse_duplicates_ETs)

replicates_metab_data <- filter(replicates_metab_data, Extraction == "NH24") %>% 
                         filter(Extraction != "Blank") %>%
                         filter(Extraction != "Empty") %>%
                         filter(Extraction != "Unknown") %>%
                         filter(Mouse != "Blank") %>%
                         filter(Mouse != "Empty") %>%
                         filter(Mouse != "Unknown")

rownames(replicates_metab_data) <- paste(replicates_metab_data$Index,
                   "Mouse",replicates_metab_data$Mouse,
                   "Strain",replicates_metab_data$Strain,
                   "Replicate:",replicates_metab_data$replicate, 
                   replicates_metab_data$Extraction)

combined_clustering_data <- rbind.data.frame(replicates_metab_data,duplicates_metab_data)

combined_clustering_matrix <- combined_clustering_data[-c(1:11)]

pdf(file = "Clustering_Results.pdf", paper = "us")

clusters_man <- hclust(dist(combined_clustering_matrix,method = "manhattan",diag = TRUE))
clusters_euc <- hclust(dist(combined_clustering_matrix,method = "euclidean",diag = TRUE))
clusters_max <- hclust(dist(combined_clustering_matrix,method = "maximum",diag = TRUE))
clusters_can <- hclust(dist(combined_clustering_matrix,method = "canberra",diag = TRUE))
clusters_bin <- hclust(dist(combined_clustering_matrix,method = "binary",diag = TRUE))
clusters_min <- hclust(dist(combined_clustering_matrix,method = "minkowski",diag = TRUE))

plot(clusters_man,cex=0.25)
plot(clusters_euc,cex=0.25)
plot(clusters_max,cex=0.25)
plot(clusters_can,cex=0.25)
plot(clusters_bin,cex=0.25)
plot(clusters_min,cex=0.25)


dev.off()
```



```{r}
#Covert factors in the Number using the model matrix command
library(cluster)
library(HSAUR)
library(fpc)
library(corrplot)


combined_corr <- cor(combined_clustering_matrix,use = "complete.obs")   # NA are removed

# Kmeans clustre analysis
res_clustering <- kmeans(combined_clustering_matrix, centers = 10)
summary(res_clustering)

col<- colorRampPalette(c("blue", "white", "red"))(20)
heatmap(x = combined_corr, col = col, symm = TRUE)
```




biorepliation same animal 
bioreps -strains 
single metabolites that is good

Add indexes for replicaites using the mod function on the sample index
```{r}
Technical_rep_1 <- filter(metab_data,replicate == "rep_1")

Index <- Technical_rep_1$Index
Match_strings <- paste(Technical_rep_1$Strain,Technical_rep_1$Age,sep = ",")


Duplicate_indicies <- sort(unique(
                      c(which(duplicated(Match_strings)),
                        which(duplicated(Match_strings,fromLast = TRUE)))))

Bioreplicate_vector <- rep.int(0, nrow(Technical_rep_1)) 
Bioreplicate_vector[Duplicate_indicies] <- 1

Bioreplicate_df <- cbind.data.frame(Index,Match_strings,Bioreplicate_vector)
Bioreplicate_df <- Bioreplicate_df[with(Bioreplicate_df, order(Match_strings)), ]

x <- inner_join(Bioreplicate_df,Technical_rep_1)

paste(Bioreplicate_df$Bioreplicate_vector,collapse = ",")

#zou need to have unqiue values in the bz mere
#can be done by selecting multiple columns
```


Prior to clustering data, remove or estimate missing data and rescale variables for comparability.
```{r}
clustering_dataset <- data[, - c(2,3,4,5,8,11)]
clustering_matrix <- clustering_dataset[1:25,-c(1:7)]
numeric_clustering_matrix <- matrix(as.numeric(unlist(clustering_matrix)),nrow=nrow(clustering_matrix))
```

Prepare Data for Clustering Analysis
```{r}
mydata <- na.omit(numeric_clustering_matrix) # listwise deletion of missing
any(is.na(mydata)) #Check any NAs
mydata <- scale(numeric_clustering_matrix) # standardize variables
```

K-means clustering partitioning Method 
This requires number of clusters to extract. 
A plot of the within groups sum of squares by number of clusters extracted can help determine the appropriate number of clusters. 
```{r}
# Determine number of clusters
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(mydata, 
  	centers=i)$withinss)

plot(1:15, wss, type="b", xlab="Number of Clusters",
  ylab="Within groups sum of squares")
```


```{r}
# K-Means Cluster Analysis
fit_kmeans <- kmeans(mydata, 5) # 5 cluster solution
# get cluster means 
aggregate(mydata,by=list(fit_kmeans$cluster),FUN=mean)
# append cluster assignment
mydata <- data.frame(mydata, fit$cluster)
```

Hierarchical Agglomerative
```{r}
# Ward Hierarchical Clustering
d <- dist(mydata, method = "euclidean") # distance matrix
fit <- hclust(d, method="ward") 
plot(fit) # display dendogram
groups <- cutree(fit, k=5) # cut tree into 5 clusters
# draw dendogram with red borders around the 5 clusters 
rect.hclust(fit, k=5, border="red")
```

The pvclust( ) function in the pvclust package provides p-values for hierarchical clustering based on multiscale bootstrap resampling. Clusters that are highly supported by the data will have large p values. 
Pvclust clusters columns, not rows. Data needs to be tarnsposed before using

```{r}
# Ward Hierarchical Clustering with Bootstrapped p values
library(pvclust)
fit_ward <- pvclust(mydata, method.hclust="ward",
   method.dist="euclidean",nboot = 10)
plot(fit) # dendogram with p values
# add rectangles around groups highly supported by the data
pvrect(fit, alpha=.95)
```

Model based approaches assume a variety of data models and apply maximum likelihood estimation and Bayes criteria to identify the most likely model and number of clusters. Specifically, the Mclust( ) function in the mclust package selects the optimal model according to BIC for EM initialized by hierarchical clustering for parameterized Gaussian mixture models. One chooses the model and number of clusters with the largest BIC.help(mclustModelNames) to details on the model chosen as best.

```{r}
# Model Based Clustering
library(mclust)
fit <- Mclust(mydata)
plot(fit) # plot results 
summary(fit) # display the best model
```

Plotting Cluster Solutions
It is always a good idea to look at the cluster results.

```{r}
# K-Means Clustering with 5 clusters
fit <- kmeans(mydata, 5)

# Cluster Plot against 1st 2 principal components

# vary parameters for most readable graph
library(cluster) 


clusplot(mydata2, fit$cluster, color=TRUE, shade=TRUE, 
  	labels=2, lines=0)

# Centroid Plot against 1st 2 discriminant functions
library(fpc)
plotcluster(mydata2, fit$cluster)
```

The function cluster.stats() in the fpc package provides a mechanism for comparing the similarity of two cluster solutions using a variety of validation criteria (Hubert's gamma coefficient, the Dunn index and the corrected rand index)
```{r}
# comparing 2 cluster solutions
library(fpc)
cluster.stats(d, fit_kmeans$cluster, fit_ward$cluster)
```



