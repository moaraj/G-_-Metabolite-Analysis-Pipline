---
title: "Correlation Plot"
author: "Moaraj_Hasan"
date: "24 April 2017"
output: 
  html_document: 
    fig_height: 7
    highlight: monochrome
    keep_md: yes
    number_sections: yes
    toc: yes
---
#Clear the environement
```{r}
#Clear Environment
rm(list = ls())
```

#Setup
```{r Setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#If on the Alineware machine Set the Working Directory to this
if(Sys.info()[['sysname']] == "Windows"){
    #Convienienve View Function
    View <- function(x){utils::View(x)}
     setwd(dir = "D:/Dropbox/Aging BXD Study/D _ Metabolomics/F _ Correlation Plots/")}

#If on the Mac Set the Working Directory to this
if(Sys.info()[['sysname']] == "Darwin"){
  View <- NULL
     setwd(dir = "/Users/mohasan/Dropbox/Aging BXD Study/D _ Metabolomics/")}

#Data import
library(readr)

#Data manipulation Packages
library(dplyr)
library(reshape2)
library(plyr)
library(tidyr)

#Column Split 
library(stringr)

#For Plotting
library(ggplot2)
library(grid)
library(gridExtra)
library(ggthemes)
library(GGally)

#MAtrix Randomoization
library(picante)

# Convienience Function the Opposite of %in%
'%!in%' <- function(x,y)!('%in%'(x,y))

# Mod function
mod<-function(x,m)
  {
    t1<-floor(x/m)
    return(x-t1*m)
}

# Finding loaded Packages and Unloading Packages
search()
```

#Multiplot Function
```{r Multiple plot function}

# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots == 1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

#Grid Arrange With Legend on the Bottom
```{r grid_arrange_shared_legend}
grid_arrange_shared_legend <- function(...) {
    plots <- list(...)
    g <- ggplotGrob(plots[[1]] + theme(legend.position = "bottom"))$grobs
    legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
    lheight <- sum(legend$height)
    grid.arrange(
        do.call(arrangeGrob, lapply(plots, function(x)
            x + theme(legend.position = "none"))),
        legend,
        ncol = 1,
        heights = unit.c(unit(1, "npc") - lheight, lheight))
}
```

#Replicate Index function
Add indexes for replicaites using the mod function on the sample index
```{r Replicate Index,message=FALSE, warning=FALSE}
Replicate_index <- function(metab_data){

if(metab_data[1,"ET"] == metab_data[2,"ET"]){
metab_data <- merge(metab_data %>% 
mutate(Replicate  = paste("rep_", rep(c(1,2), times = dim(metab_data)[1]/2), sep = "")) %>% 
dplyr::select(Ion, Replicate), metab_data, by = "Ion")
#you need to have unqiue values in the bz mere
#can be done by selecting multiple columns

} else 
  
if( metab_data[1,"ET"] != metab_data[2,"ET"]) {
metab_data <- merge(metab_data %>% 
mutate(Replicate  = "rep_1") %>% dplyr::select(Ion, Replicate), metab_data, by = "Ion")  
}
  
return(metab_data)
}
```

```{r}
make.age.cohorts <- function(metab_data)

library(gtools)
quartiles <- quantcut(metab_data, seq(0,4,by=1) )

table(deciles)

library(plyr)


ddply(dataset, "teams", function(metab_data){
  

  age_quartile <- cut(x = metab_data$time_spent, 
                       breaks = quantile(na.omit(metab_data$Age)),
                       labels = FALSE,
                       include.lowest = TRUE)

  data.frame(team, team_quartile)
})

```



#Metabolite Data Import
```{r}
metab_data0 <- read.delim(file = "3.csv_evan1.csv", sep = ";")
metab_data1 <- read.delim(file = "3.csv_moaraj1.csv", sep = ";")
metab_data3 <- read.delim(file = "3.csv_moaraj3.csv", sep = ";")
metab_data4 <- read.delim(file = "3.csv_moaraj4.csv", sep = ";")

metab_data0 <- cbind.data.frame("Science",metab_data0)
metab_data1 <- cbind.data.frame("Opt1",metab_data1)
metab_data3 <- cbind.data.frame("Opt3",metab_data3)
metab_data4 <- cbind.data.frame("FullRun1",met
                                ab_data4)

names(metab_data0)[1] <- "Dataset"
names(metab_data1)[1] <- "Dataset"
names(metab_data3)[1] <- "Dataset"
names(metab_data4)[1] <- "Dataset"

names(metab_data0)[2] <- "Ion"
names(metab_data1)[2] <- "Ion"
names(metab_data3)[2] <- "Ion"
names(metab_data4)[2] <- "Ion"

metab_data0 <- Replicate_index(metab_data0)
metab_data1 <- Replicate_index(metab_data1)
metab_data3 <- Replicate_index(metab_data3)
metab_data4 <- Replicate_index(metab_data4)
```


#Upset Analysis
```{r}
library(UpSetR)
Metabolite_Venn_Data <- list(Science_Paper = names(metab_data0),
                        #Optimization_1 = names(metab_data1),
                        #Optimization_3 = names(metab_data3),
                        Full_Run = names(metab_data4))

Metabolite_Venn <- upset(fromList(Metabolite_Venn_Data), order.by = "freq",
                         line.size = 2, point.size = 4)

Metabolite_Venn
```

#HMDB Lookup

```{r}
HMDB_Lookup <- function(metabolite.data){
  
  metabolite.names <- colnames(metabolite.data)[12:ncol(metabolite.data)]
  metabolite.names.dup <- which(nchar(metabolite.names) != 9)
  metabolite.names.fin <- metabolite.names[-metabolite.names.dup]
  
  res <- sapply( metabolite.names.fin, FUN = function(x) {
      #Look up in local 
      hmdb_dir <- file.path("..","Y_hmdb_database")
      data_xml <- file.path(hmdb_dir, paste(x,".xml",sep = ""))

      if(file.exists(data_xml)){
            xmlfile <- xmlNativeTreeParse(data_xml, 
                                useInternalNodes = TRUE, 
                                addAttributeNamespaces = TRUE)
      
            xmltop <- xmlRoot(xmlfile) #gives content of root
            xmlValue(xmltop[["name"]])
      }  
  })
  
  nullToNA <- function(x) {
    x[sapply(x, is.null)] <- "Missing.from.HMDB"
    return(x)
  }
  
  res <- nullToNA(res)
  
  x1 <- names(res)
  x2 <- as.character(unlist(res[1:length(res)]))
  
  HMDB.Dict <- cbind.data.frame(x1,x2)
  row.names(HMDB.Dict) <- NULL
  colnames(HMDB.Dict) <- c("HMDB.Id","Metabolite.Name")
  return(HMDB.Dict)
}

```


Correlation Plot Between the 3rd Optimization and Current Study
Plot of well seperated Metabolite over Diet
```{r}

x <- filter(metab_data4, Replicate == "rep_1") %>% dplyr::select(HMDB02038)
y <- filter(metab_data4, Replicate == "rep_2") %>% dplyr::select(HMDB02038)

x <- filter(metab_data4, Diet == "HF") %>% dplyr::select(HMDB02038)
y <- filter(metab_data4, Diet == "CD") %>% dplyr::select(HMDB02038)

plot(cbind.data.frame(y[1:700,],x[1:700,]))
```


#Get the Plots for the replicates
```{r }
rep_corr_plots <- pairWiseCor(
          (filter(metab_data4, Replicate == "rep_1") %>% 
             dplyr::select(-one_of(factor_cols, "Age.Cohort"))),
          (filter(metab_data4, Replicate == "rep_2") %>% 
             dplyr::select(-one_of(factor_cols, "Age.Cohort")))
                             )

rep_corr_plots <- melt(rep_corr_plots)

pdf("7.Rep_Corr_Plot.pdf", paper ="usr")
ggplot(data = rep_corr_plots, aes(x = rep_corr_plots$value, fill = rep_corr_plots$variable)) + 
geom_histogram(binwidth = .005) + facet_wrap(~variable, scales = 'free_x', ncol = 2) + 
#theme_bw() + 
scale_fill_brewer(palette="Set1") + 
scale_y_continuous(name = "") +
scale_x_continuous(name = "Correlation Coefficient", limits = c(0.4,1.0)) 
dev.off()
```

#Overlapping Subsets Function
```{r}
Overlapping_Subsets <- function(metab_data_1, metab_data_2)  {
  
print("Selecing the metabolites Common in both datasets")
mdata_intercept <- intersect(names(metab_data_1),
                             names(metab_data_2))

metab_data_1 <- metab_data_1 %>%
     select(one_of(mdata_intercept))

metab_data_2 <- metab_data_2 %>%
     select(one_of(mdata_intercept))

print("Aggregating Mice by Diet and Strain Means")
strain_means_1 <- aggregate(metab_data_1,
                            by = list(metab_data_1$Strain), 
                            FUN = mean)

strain_means_2 <- aggregate(metab_data_2,
                            by = list(metab_data_2$Strain), 
                            FUN = mean)


print("Selecting the Mouse Strains common 
in both datasets after aggregation")

strain_intercept <- intersect(strain_means_1$Group.1,
                              strain_means_2$Group.1)

corr_data_1 <- strain_means_1 %>%
     filter(Group.1 %in% strain_intercept)

corr_data_2 <- strain_means_2 %>%
     filter(Group.1 %in% strain_intercept)

print("Determining Factor Columns")
factor_cols <- names(metab_data_1[1:11])

print("Removing Factor Columns for Correlation Function")
corr_data_1 <- corr_data_1 %>% select(-one_of(factor_cols))
corr_data_2 <- corr_data_2 %>% select(-one_of(factor_cols))

return(  list(X1 = corr_data_1[-1],
              X1.names = corr_data_1[1],
              X2 = corr_data_2[-1],
              X2.names = corr_data_2[1])  )
}
```

#Pairwaise Correlation Graph 
```{r}
pairWiseCor <- function(metab_data_1,metab_data_2){

    
  pairs.1 <- names(metab_data_1)
  pairs.2 <- names(metab_data_2)
  pairs.df <- cbind(pairs.1, pairs.2)
  
  df <- data.frame (Variable1 = rep(0,nrow(pairs.df)),
                    Variable2 = rep(0, nrow(pairs.df)),
                    AbsSpearCor = rep(0, nrow(pairs.df)),
                    SpearCor = rep(0, nrow(pairs.df)),
                    AbsPearCor = rep(0, nrow(pairs.df)),
                    PearCor = rep(0, nrow(pairs.df)),
                    AbsKenCor = rep(0, nrow(pairs.df)),
                    KenCor = rep(0, nrow(pairs.df))) 
  
  for(i in 1:nrow(pairs.df)){

  print(paste("Computing Correlation Between",
              pairs.1[i], "and" ,pairs.2[i]))
    
  print(paste(i,"Iterations of Total", nrow(pairs.df)))

    df[i,1] <- pairs.1[i]
    df[i,2] <- pairs.2[i]
    
    df[i,3] <- abs(cor(method = "spearman",cbind.data.frame(metab_data_1[,i],metab_data_2[,i])))[1,2]
    df[i,4] <- cor(method = "spearman",cbind.data.frame(metab_data_1[,i],metab_data_2[,i]))[1,2]

    df[i,5] <- abs(cor(method = "pearson",cbind.data.frame(metab_data_1[,i],metab_data_2[,i]))[1,2])
    df[i,6] <- cor(method = "pearson",cbind.data.frame(metab_data_1[,i],metab_data_2[,i]))[1,2]
    
    df[i,7] <- abs(cor(method = "kendall", cbind.data.frame(metab_data_1[,i],metab_data_2[,i]))[1,2])
    df[i,8] <- cor(method = "kendall",cbind.data.frame(metab_data_1[,i],metab_data_2[,i]))[1,2]
  
  }
  return(df)
}
```

#Overlap between the SCeince and hte Full Run metabolites
```{r}
overlap_metabs <- Overlapping_Subsets(metab_data0,metab_data4)
Science_FullRun <- pairWiseCor(overlap_metabs$X1,overlap_metabs$X2)

Science_FullRun_plot <- melt(Science_FullRun)
ggplot(data = Science_FullRun_plot, aes(x = Science_FullRun_plot$value, fill = Science_FullRun_plot$variable)) + 
geom_histogram(binwidth = .05) + facet_wrap(~variable, scales = 'free_x', ncol = 2) + 
scale_fill_brewer(palette="Set1") + 
scale_y_continuous(name = "") +
scale_x_continuous(name = "Correlation Coefficient") 
```

#Boot Strapping Function
```{r}
correlation_bootstrap <- function(data_1,data_2,randomize,nboot,boot.subsample) {

if(nboot > 1){
  res.df <- data.frame(Variable1 = 0,
                   Variable2 = 0,
                   variable  = 0,
                   value     = 0,
                   nboot     = 0,
                   random    = 0)

  res.df <- res.df[-1,]

  for (i in 1:nboot) {
    
    if(randomize == 1) {
  
    print("Performing Covaraince Determination on the Randomized Rows in Frist Data Set")
    
    data_1_matrix <- data.matrix(data_1)
    data_1_matrix <- remove_matrix_na(data_1_matrix)
    data_1_rand <- randomizeMatrix(data_1_matrix,null.model = "frequency",iterations = 1000)
    data_1_rand <- data.frame(data_1_rand)
    
    data_2_matrix <- data.matrix(data_2)
    data_2_matrix <- remove_matrix_na(data_2_matrix)
    data_2_rand <- randomizeMatrix(data_2_matrix,null.model = "frequency",iterations = 1000)
    data_2_rand <- data.frame(data_2_rand)
    
    } else if (randomize != 1) {data_1_rand <- data_1; data_2_rand <- data_2}
    
  parwise_correlations <- pairWiseCor(data_1_rand,data_2_rand)
  parwise_correlations_melt <- melt(parwise_correlations)
  iteration_vector <- c(rep(i, nrow(parwise_correlations_melt)))
  
  iteration_vector <- cbind(parwise_correlations_melt, iteration_vector)
  
  #Addeding Scrambled or Normal Data Column
  if(randomize == 1) {
  
  random_vector <- (rep("Scrambled Data", nrow(parwise_correlations_melt)))
  iteration_vector <- cbind(iteration_vector, random_vector)
  
  } else if (randomize != 1) {
  
  random_vector <- (rep("Normal Data", nrow(parwise_correlations_melt)))
  iteration_vector <- cbind(iteration_vector, random_vector)
  
  }
  
  colnames(iteration_vector) <- names(res.df)
  res.df <- rbind.data.frame(res.df, iteration_vector)
  
    }
  
return(res.df)

} else if  (nboot == 1) {res.df <- pairWiseCor(data_1,data_2)
                         res.df <- melt(res.df)
res.df <- res.df[-1,]
res.df <- na.omit(res.df)
return(res.df)

    }
  }
```

#For Debugging
```{r, eval=FALSE, include=FALSE}
data_1 <- metab_data0
data_2 <- metab_data4 

metab_data_1 <- metab_data0
metab_data_2 <- metab_data4 

i = 1
randomize = 1
nboot = 10
boot.subsample = 10
```

#Remove Debugging Variables from global Environment
```{r}
remove(data_1)
remove(data_2)

remove(metab_data_1)
remove(metab_data_2)

remove(i)
remove(randomize)
remove(nboot)
remove(boot.subsample)
```


#Overlap Between the Science and the Full Run Metabolites with HF
```{r}
Corr_Bootstrap_Master_Function <- function(metab_data_1,metab_data_2,
                                       randomize,nboot,boot.subsample) {

overlap_metabs <- Overlapping_Subsets(metab_data_1,metab_data_2)

data_1 <- overlap_metabs$X1
data_2 <- overlap_metabs$X2

res.df <- correlation_bootstrap(data_1,data_2, randomize, nboot, boot.subsample)

res.df$random <- factor(res.df$random)
res.df$variable <- factor(res.df$variable)

return(res.df)
}
```


```{r}
y1.10 <- Corr_Bootstrap_Master_Function(metab_data0, 
                                    metab_data4, 
                                    randomize = 0, 
                                    nboot = 10, 
                                    boot.subsample = 100)

y2.10 <- Corr_Bootstrap_Master_Function(metab_data0, 
                                    metab_data4, 
                                    randomize = 1, 
                                    nboot = 10, 
                                    boot.subsample = 100)

HF <- function(x) {filter(x, Diet == "HF")}
CD <- function(x) {filter(x, Diet == "CD")}

y1.10.HF <- Corr_Bootstrap_Master_Function(HF(metab_data0), 
                                       HF(metab_data4), 
                                       randomize = 0, nboot = 10, boot.subsample = 100)

y2.10.HF <- Corr_Bootstrap_Master_Function(HF(metab_data0), 
                                       HF(metab_data4), 
                                       randomize = 1, nboot = 10, boot.subsample = 100)

y1.10.CD <- Corr_Bootstrap_Master_Function(CD(metab_data0), 
                                       CD(metab_data4), 
                                       randomize = 0, 
                                       nboot = 10, boot.subsample = 100)

y2.10.CD <- Corr_Bootstrap_Master_Function(CD(metab_data0), 
                                       CD(metab_data4), 
                                       randomize = 1, nboot = 10, boot.subsample = 100)

```

Perform 100 Boot Strap Iterations

```{r}
y1.100 <- Corr_Bootstrap_Master_Function(metab_data0, 
                                         metab_data4, 
                                         randomize = 0,
                                         nboot =  100,
                                         boot.subsample =  100)

y2.100 <- Corr_Bootstrap_Master_Function(metab_data0,
                                         metab_data4,
                                         randomize = 1,
                                         nboot = 100,
                                         boot.subsample =  100)
```


#Parallelize the Code


```{r}
library(foreach)
library(doParallel)
library(parallel)

numCores <- detectCores()
cl <- makeCluster(numCores)
registerDoParallel(cl)

inputs <- 1:10
processInput <- function(i) {
  i * i
}

results <- foreach(i=inputs) %dopar% {
  processInput(i)
}
```

#Basic Parallelization Check
```{r}
bench.par <- microbenchmark::microbenchmark(
results <- foreach(i=nboot) %dopar% {
  i * 10
} 
,times = 1000)

bench.sin <- microbenchmark::microbenchmark(
results <- for(i in 1:nboot) {
  i * 10
}
,times = 1000)

bench.df <- cbind(bench.par,bench.sin[-1])
colnames(bench.df) <- c("Objective","Parrallel","Serial")
bench.df[1] <- 1:nrow(bench.df)
m.bench.df <- melt(bench.df,id.vars = "Objective")
m.bench.df$value <- m.bench.df$value/1E6

ggplot(data = m.bench.df, aes(x = m.bench.df$variable,
                              y = m.bench.df$value )) + 
        geom_point(inherit.aes = FALSE, 
                   aes(colour = m.bench.df$value,
                       x = m.bench.df$variable,
                       y = m.bench.df$value,
                       alpha = 0.5),
                   position = position_jitter(width = 0.5)) + 
  scale_colour_gradient2() +
        geom_boxplot(outlier.colour = NA, fill = NA, width = 0.5) + 
  scale_y_continuous(name = "Processor Runtime (seconds)",limits = c(0,60)) + 
  theme_light() 


```



```{r}


pdf(file = "8.Correlation_Science_Full_run.CD.pdf", paper = "legal")
p1 <- plotting_res3.df(rbind(y1.10,y2.10))
p2 <- plotting_res2.df(rbind(y1.10,y2.10))

dev.off()

pdf(file = "8.Correlation_Science_Full_run.CD.pdf", paper = "legal")
p3 <- plotting_res3.df(rbind(y1.10.CD,y2.10.CD))
p4 <- plotting_res2.df(rbind(y1.10.CD,y2.10.CD))

dev.off()

pdf(file = "8.Correlation_Science_Full_run.HF.pdf", paper = "legal")
p5 <- plotting_res3.df(rbind(y1.10.HF,y2.10.HF))
p6 <- plotting_res2.df(rbind(y1.10.HF,y2.10.HF))

dev.off()



```


#Plotting res.df
```{r}

plotting_res2.df <- function(x){
# Histogram overlaid with kernel density curve
p.2 <- ggplot(x, aes(x=value)) + 
    geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
                   binwidth=.025,
                   colour="black", fill="white") +
    geom_density(alpha=.2, fill="#FF6666")  + # Overlay with transparent density plot
    facet_wrap(~ random)
return(p.2)
}

plotting_res3.df <- function(y){
# Histogram overlaid with kernel density curve
p.3 <- ggplot(y, aes(x=value)) + 
    geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
                   binwidth=.025,
                   colour="black", fill="white") +
    geom_density(alpha=.2, fill="#FF6666") + # Overlay with transparent density plot
    facet_wrap(~ variable + random,ncol = 2,scales = "free")

return(p.3)
}

```


#Importing Gene Data
```{r}

gene_data_t <- read.csv(file = "../F _ Correlation Plots Genes/Heart_data.csv", 
                        sep = ";",header = TRUE)

strain.names <- colnames(gene_data_t)
strain.names[1] <- "Strain"
colnames(gene_data_t) <- strain.names

gene_data_t %>% mutate_if(is.factor, as.character) -> gene_data_t
gene.names <- gene_data_t$Strain

#Transpose just the number in the data frame
gene_data <- as.data.frame(t(gene_data_t[2:ncol(gene_data_t)]))

#Add strains to column 1
gene_data <- cbind.data.frame(strain.names[-1],gene_data)

#make the genenames the columns
colnames(gene_data) <- c("Strain", gene.names)


gene_data <- gene_data %>% separate(Strain, c("Strain", "Diet"),"_")



gene_boot <- Succinct_Plotting_Function(filter(gene_data, Diet == "Chow"),
                                        filter(gene_data, Diet == "HiFat"),
                                        randomize = 0, nboot = 3, boot.subsample = 10000)

gene_boot_scrambled <- Succinct_Plotting_Function(filter(gene_data, Diet == "Chow"),
                                        filter(gene_data, Diet == "HiFat"),
                                        randomize = 1, nboot = 3, boot.subsample = 10000)

gene_plot <- plotting_res3.df(rbind(gene_boot,gene_boot_scrambled))


```

```{r}
Emperical_FDR <- function(boot,scrambled_boot){
  FDR.df <- cbind.data.frame(gene_boot[1],
                             gene_boot$variable,
                             gene_boot$value - gene_boot_scrambled$value)
  colnames(FDR.df) <- c("Variable", "Correlation.Coefficient", "FDR")

  return(FDR.df)  
}

FDR.df <- Emperical_FDR(gene_boot, gene_boot_scrambled)
plotting_res4.df(FDR.df)

```





```{r}

# Histogram overlaid with kernel density curve


coeff.filt <- function(x,i){
  coeffs <- as.character(unique(x$variable))
  n <- coeffs[i]
  x <- filter(x, variable == n)
  return(x)
  }


FDR.data <- function(data1,data2,i){

data1 <- coeff.filt(data1,i)
data2 <- coeff.filt(data2,i)

data1 <- data1$value
data2 <- data2$value

x = density(data1, from= range(c(data1, data2))[1], 
                 to=range(c(data1, data2))[2])$x

y1 = abs(        density(data1, from= range(c(data1, data2))[1], 
                 to=range(c(data1, data2))[2] )$y - (density(data1, from= range(c(data1, data2))[1], 
                 to=range(c(data1, data2))[2] )$y - density(data2,  
                 from= range(c(data1, data2))[1], 
                 to=range(c(data1, data2))[2])$y)         
        )

y2 = abs(        density(data2, 
                         from= range(c(data1, data2))[1],
                         to=range(c(data1, data2))[2])$y - 
                   (density(data1, from= range(c(data1, data2))[1], 
                            to=range(c(data1, data2))[2] )$y - 
                      density(data2,from= range(c(data1, data2))[1],
                              to=range(c(data1, data2))[2])$y)         
        )

y3 = abs((density(data1, from= range(c(data1, data2))[1], 
                 to=range(c(data1, data2))[2] )$y - density(data2,  
                 from= range(c(data1, data2))[1], 
                 to=range(c(data1, data2))[2])$y))

df <- cbind.data.frame(x,y1,y2,y3)

}

corr.df <- rbind.data.frame( FDR.data(gene_boot,gene_boot_scrambled,1),
                        #FDR.data(gene_boot,gene_boot_scrambled,2),
                        FDR.data(gene_boot,gene_boot_scrambled,3),
                        #FDR.data(gene_boot,gene_boot_scrambled,4),
                        FDR.data(gene_boot,gene_boot_scrambled,5)
                        #FDR.data(gene_boot,gene_boot_scrambled,6)
                      )

corr.df$corr <-gsub(df$corr,pattern = 1,replacement = "Pearson Correlation")
corr.df$corr <-gsub(df$corr,pattern = 3,replacement = "Spearman Correlation")
corr.df$corr <-gsub(df$corr,pattern = 5,replacement = "Kendall Correlation")

colnames(corr.df)
ggplot(data = corr.df, aes(x = x, y = y3, colour = factor(corr))) + 
geom_point() + geom_line() +
scale_x_continuous(limits = c(0,1)) + theme_grey() + 
xlab("Correlation Coefficient") +
ylab("Difference in Null and Signal Densities") +
ggtitle("Emperical False Discovery Rate of Genetic Data", subtitle = NULL) +
theme(axis.title.y = element_text(size = 14),axis.title.x = element_text(size = 14)) +
  
geom_hline(aes(yintercept = 0.1), colour = "black", size = 1, linetype = "dashed")  + 
geom_text(aes(0.1,.1,label = "10% Cut off", vjust = -0.3), color = "black", size = 6) + 
  
geom_hline(aes(yintercept = 0.5), colour = "black", size = 1, linetype = "dashed")  + 
geom_text(aes(0.1,.5,label = "50% Cut off", vjust = -0.3), color = "black", size = 6) + 
  
theme(legend.position = c(0.75, 0.5),
      legend.background = element_rect(fill="lightgrey",
      size=0.5 , linetype="solid", colour ="black")) +
scale_color_manual(name = "Correlation Coefficients",
                   labels = c("Pearson Correlation", 
                              "Spearman Correlation",
                              "Kendall Correlation"), values = c("blue", "red","green")) 



```



#Multi AOV Script
```{r}
AOV_Script <- function(metab_data,metab){
  
  #Set up variables for the aov analysis
  counts <- as.matrix(log(metab_data[metab]))
  colnames(counts) <- "counts"
  factor.columns <- metab_data[1:11]
  metabmatrix <- cbind.data.frame(factor.columns,counts)
  
  fit <- aov(formula = as.formula("counts ~ Diet + Replicate + Sex + Age.Cohort + Strain"), 
             data = metab_data)
  
  fit2 <- glm(formula = as.formula("counts ~ Diet + Replicate + Sex + Age.Cohort + Strain"), 
              data = metab_data)
  
  return(fit)
}


fit_summ <- AOV_Script(metab_data4,13)

```

```{r}
nfactor.cols = 11
metab_data <- metab_data1
inputs <- 12:20
```

```{r}
remove(nfactor.cols)
remove(metab_data)
remove(inputs)
```


```{r}

run.aov.par <- function(ncores,nfactor.cols,metab_data){

require(foreach)
require(doParallel)
require(parallel)

if(missing(ncores)){
  print("Cores Not Specified, Using All Cores")
numCores <- detectCores()
cl <- makeCluster(numCores - 1)
registerDoParallel(cl)
} else {
  cl <- makeCluster(ncores)
  registerDoParallel(cl)
}


# The function I was to run in parrallel
  # Needs to be ititlized in the new R environment
  
clusterExport(cl=cl, 
              list("metab_data"),
              envir=environment())

AOV_Script <- function(metab_data,metab){
  
  #Set up variables for the aov analysis
  counts <- as.matrix(log(metab_data[metab]))
  colnames(counts) <- "counts"
  factor.columns <- metab_data[1:11]
  metabmatrix <- cbind.data.frame(factor.columns,counts)
  
  fit <- aov(formula = as.formula("counts ~ Diet + Replicate + Sex + Age.Cohort + Strain"), 
             data = metab_data)
  
  fit2 <- glm(formula = as.formula("counts ~ Diet + Replicate + Sex + Age.Cohort + Strain"), 
              data = metab_data)
  
  
  return(fit)
}
  
inputs <- (nfactor.cols + 1):ncol(metab_data)
processInput <- function(i) {
  AOV_Script(metab_data,i)
}

results <- foreach(i=inputs) %dopar% {
  processInput(i)
}

return(results)

stopCluster(cl)
}

mres.data1 <- run.aov.par(ncores = 7,nfactor.cols = 11,metab_data1)

```

```{r}

drop.useless.factors <- function(DF){DF[, sapply(DF, function(col) length(unique(col))) > 1]}
metab.4.filt <- drop.useless.factors(metab_data4)

metab.4.full.factorized <- as.data.frame(lapply(metab_data4[1:11],as.factor))
metab.4.full.factorized <- cbind.data.frame(metab.4.full.factorized,
                                            metab_data4[12:ncol(metab_data4)])

```

```{r}
#Diet based filtering
metab.4.filt.diet <- cbind.data.frame(metab.4.filt[7],metab.4.filt[11:ncol(metab.4.filt)])
metab.4.filt.diet.bin <- metab.4.filt.diet
metab.4.filt.diet.bin[1] <- gsub(metab.4.filt.diet[1], pattern = "CD",replacement = 0)
metab.4.filt.diet.bin[1] <- gsub(metab.4.filt.diet[1], pattern = "HF",replacement = 1)

```

```{r}
library(Amelia)
missmap(metab.4.filt.diet.bin, main = "Missing values vs observed")


fit3 <- glm(formula = as.formula("Strain ~ ."), 
            data = metab4.data[-c(1:6, 8:12)],
            family = binomial(link = "logit"))

summary(fit3)

```

```{r}
library(ggfortify)
autoplot(lm(Petal.Width ~ ., data = metab4.data), label.size = 3)
```



#Exploratory PCA and Factor anaylsis


Generate Data for PCA analysis
```{r}

  
  
  
convert.ids <- function(data){
  
  match.df <- HMDB_Lookup(data)
  list.match <- match(colnames(data),match.df$HMDB.Id)
                
  
  no.match <- which(is.na(list.match))
  list.match.fin <- list.match[!is.na(list.match)]
  
  colnames(data)[-no.match] <- as.character(match.df[list.match.fin,2])
  
  colnames(data) <- gsub('-','_',colnames(data))
  colnames(data) <- gsub(' ','.',colnames(data))
  
  return(data)

}

metab4.data <- convert.ids(metab_data4)

#strain.sample <- as.character(sample(unique(metab_data0$Strain),size = 10,replace = FALSE))

metab4.data <- metab4.data %>% setNames(make.names(names(.), unique = TRUE)) %>% 
  select(- contains('Missing.from.HMDB')) %>% 
  filter(Diet %in% c("HF","CD")) %>%
  select(-contains('PS.')) %>%
  select(-contains('PC.')) %>%
  select(-contains('PG.')) %>%
  select(-contains('PE.'))



#%>% filter(Strain %in% strain.sample)

metab4.data[13:ncol(metab4.data)] <- log(metab4.data[13:ncol(metab4.data)])

PCA_dataset <-data.matrix(metab4.data[12:ncol(metab4.data)])
PCA_dataset.log <-log(data.matrix(metab4.data[12:ncol(metab4.data)]))

library(ggfortify)

autoplot(kmeans(PCA_dataset, 2), data = metab4.data)
autoplot(kmeans(PCA_dataset, 2), data = metab4.data, label = TRUE, label.size = 3)

library(cluster)

autoplot(pam(PCA_dataset, 2), frame = TRUE, frame.type = 'norm')
autoplot(fanny(PCA_dataset, 2), frame = TRUE)

autoplot(pam(PCA_dataset.log, 2), frame = TRUE, frame.type = 'norm')
autoplot(fanny(PCA_dataset.log, 2), frame = TRUE)


library(lfda)

# Local Fisher Discriminant Analysis (LFDA)
model <- lfda(x = PCA_dataset, y = metab4.data[,3], 4, metric="plain")
autoplot(model, data = metab4.data, frame = TRUE, frame.colour = 'Diet')
autoplot(model, data = metab4.data, frame = TRUE, frame.colour = 'Sex')
autoplot(model, data = metab4.data, frame = TRUE, frame.colour = 'Strain')
autoplot(model, data = metab4.data, frame = TRUE, frame.colour = 'Age.Cohort')
autoplot(model, data = metab4.data, frame = TRUE, frame.colour = 'Replicate')



# Kernel Local Fisher Discriminant Analysis (KLFDA)
model2 <- klfda(kmatrixGauss(PCA_dataset), metab4.data[,3], 4, metric="plain")
autoplot(model2, data = metab4.data, frame = TRUE, frame.colour = 'Diet')
autoplot(model2, data = metab4.data, frame = TRUE, frame.colour = 'Sex')
autoplot(model2, data = metab4.data, frame = TRUE, frame.colour = 'Strain')
autoplot(model2, data = metab4.data, frame = TRUE, frame.colour = 'Age.Cohort')
autoplot(model2, data = metab4.data, frame = TRUE, frame.colour = 'Replicate')

# Semi-supervised Local Fisher Discriminant Analysis (SELF)
model3 <- self(PCA_dataset, metab4.data[,3], beta = 0.2, r = 5, metric="plain")
autoplot(model3, data = metab4.data, frame = TRUE, frame.colour = 'Diet')


```


Plotting Classical (Metric) Multidimensional Scaling
```{r}

plot(dist(PCA_dataset))

autoplot(cmdscale(dist(PCA_dataset), eig = TRUE), label = TRUE, label.size = 3)

library(MASS)
autoplot(sammon(dist(PCA_dataset)), shape = FALSE, label.colour = 'blue', label.size = 3)
```

http://rpubs.com/sinhrks/plot_pca

```{r}
    
  PCA_res <- prcomp(PCA_dataset,scale. = TRUE)
  
#pdf(file = "PCA_Plots.pdf", width = 16,height = 9)
  autoplot(prcomp(PCA_dataset), data = data, colour = 'Strain')
  autoplot(prcomp(PCA_dataset), data = data, colour = 'ET') + 
         theme(legend.position="none")
  autoplot(prcomp(PCA_dataset), data = data, colour = 'replicate')
  autoplot(prcomp(PCA_dataset), data = data, colour = 'Sex')
  autoplot(prcomp(PCA_dataset), data = data, colour = 'Diet')
  autoplot(prcomp(PCA_dataset), data = data, colour = 'Age.Cohort')
  autoplot(prcomp(PCA_dataset), data = data, colour = 'Extraction')

#Passing loadings = TRUE draws eigenvectors.
  autoplot(prcomp(PCA_dataset), 
           data = data, 
           colour = 'Diet', 
           loadings = TRUE, 
           loadings.label = TRUE, 
           loadings.colour = "blue",
           loadings.label.size = 1)

```



```{r}
# Pricipal Components Analysis
# entering raw data and extracting PCs 
# from the correlation matrix 

fit <- princomp(PCA_dataset, cor=TRUE)
summary(fit) # print variance accounted for 
loadings(fit) # pc loadings 
plot(fit, type="bar") # scree plot 
fit$scores # the principal components
biplot(fit,pc.biplot = 1, lenght = 20, width = 20)
```


Exploratory Factor Analysis
The factanal( ) function produces maximum likelihood factor analysis.
```{r}
# Maximum Likelihood Factor Analysis
# entering raw data and extracting 3 factors, 
# with varimax rotation 
fit <- factanal(PCA_dataset, factors = 10, rotation="varimax")

print(fit, digits=2, cutoff=.3, sort=TRUE)
# plot factor 1 by factor 2 
load <- fit$loadings[,1:2] 
plot(load,type="n") # set up plot 
text(load,labels=names(PCA_dataset),cex=.7) # add variable names
```


Determining the Number of Factors to Extract
A crucial decision in exploratory factor analysis is how many factors to extract. 
The nFactors package offer a suite of functions to aid in this decision. 
Of course, any factor solution must be interpretable to be useful.
```{r}
# Determine Number of Factors to Extract
library(nFactors)
ev <- eigen(cor(PCA_dataset)) # get eigenvalues
ap <- parallel(subject=nrow(PCA_dataset),
               var=ncol(PCA_dataset),
               rep=10,cent=.05)

nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)

plotnScree(nS)

plot(c(1:354),nS$Analysis$Eigenvalues, 
     xlim = c(0,50), type = "b")
lines(c(1:354),nS$Analysis$Cumu, col = "red")
lines(c(1:354),nS$Analysis$Par.Analysis, col = "blue")
lines(c(1:354),nS$Analysis$Pred.eig)

```

From the nFactors Analysis the optimal number of groups 
for the metabolic data seems to be around 31
```{r}
d.factanal <- factanal(PCA_dataset, factors = 31, scores = 'regression')
autoplot(d.factanal, data = PCA_dataset, colour = 'Diet')

autoplot(d.factanal, label = TRUE, label.size = 3,
         loadings = TRUE, loadings.label = TRUE, loadings.label.size  = 3)
```


The FactoMineR package offers a large number of additional functions for exploratory factor analysis. This includes the use of both quantitative and qualitative variables, 
as well as the inclusion of supplimentary variables and observations. 
```{r}
# PCA Variable Factor Map 
library(FactoMineR)
# graphs generated automatically
result <- PCA(PCA_dataset, graph = TRUE,scale.unit = TRUE)

result <- PCA(PCA_dataset, 
              graph = TRUE,
              scale.unit = TRUE)

m <- cbind.data.frame(result$var[1])

plot(result$eig$eigenvalue, ylim = c(0,100), xlim = c(0,40), type = "b")
lines(result$eig$`percentage of variance`, type = "b", col = "red")
lines(result$eig$`cumulative percentage of variance`, type = "b", col = 'blue')
View(m)
```


Generate Data that is more Amenable to Cluster Analysis Tooks in ggfortify
```{r}
Cluster_dataset <- data.matrix(data[14:30], rownames.force = NA)
data_replicate <- data[1:365]
```


{ggfortify} supports cluster::clara, cluster::fanny, cluster::pam classes. Because these instances should contains original data in its property, there is no need to pass original data explicitly.
```{r}
library(cluster)
Cluster_dataset <- data.matrix(data[14:365], rownames.force = NA)
colnames(Cluster_dataset) <- gsub(colnames(Cluster_dataset),pattern = " ", replacement = ".")
autoplot(clara(Cluster_dataset, 368,correct.d = TRUE))
```


#Hirarchial Clustering to Determine if Biological Replicates Cluster Together
```{r}
duplicates_metab_data <- filter(metab_data, Extraction == "NH24_D") %>% 
                         filter(Extraction != "Blank") %>%
                         filter(Extraction != "Empty") %>%
                         filter(Extraction != "Unknown") %>%
                         filter(Mouse != "Blank") %>%
                         filter(Mouse != "Empty") %>%
                         filter(Mouse != "Unknown")

rownames(duplicates_metab_data) <- paste(duplicates_metab_data$Index,
                                         "Mouse:", duplicates_metab_data$Mouse, 
                                         "Strain:", duplicates_metab_data$Strain,
                                         "Replicate:",duplicates_metab_data$replicate,
                                         duplicates_metab_data$Extraction)

mouse_duplicates_ETs <- unique(duplicates_metab_data$Mouse)
replicates_metab_data <- filter(metab_data, Mouse %in% mouse_duplicates_ETs)

replicates_metab_data <- filter(replicates_metab_data, Extraction == "NH24") %>% 
                         filter(Extraction != "Blank") %>%
                         filter(Extraction != "Empty") %>%
                         filter(Extraction != "Unknown") %>%
                         filter(Mouse != "Blank") %>%
                         filter(Mouse != "Empty") %>%
                         filter(Mouse != "Unknown")

rownames(replicates_metab_data) <- paste(replicates_metab_data$Index,
                   "Mouse",replicates_metab_data$Mouse,
                   "Strain",replicates_metab_data$Strain,
                   "Replicate:",replicates_metab_data$replicate, 
                   replicates_metab_data$Extraction)

combined_clustering_data <- rbind.data.frame(replicates_metab_data,duplicates_metab_data)

combined_clustering_matrix <- combined_clustering_data[-c(1:11)]

pdf(file = "Clustering_Results.pdf", paper = "us")

clusters_man <- hclust(dist(combined_clustering_matrix,method = "manhattan",diag = TRUE))
clusters_euc <- hclust(dist(combined_clustering_matrix,method = "euclidean",diag = TRUE))
clusters_max <- hclust(dist(combined_clustering_matrix,method = "maximum",diag = TRUE))
clusters_can <- hclust(dist(combined_clustering_matrix,method = "canberra",diag = TRUE))
clusters_bin <- hclust(dist(combined_clustering_matrix,method = "binary",diag = TRUE))
clusters_min <- hclust(dist(combined_clustering_matrix,method = "minkowski",diag = TRUE))

plot(clusters_man,cex=0.25)
plot(clusters_euc,cex=0.25)
plot(clusters_max,cex=0.25)
plot(clusters_can,cex=0.25)
plot(clusters_bin,cex=0.25)
plot(clusters_min,cex=0.25)


dev.off()
```



```{r}
#Covert factors in the Number using the model matrix command
library(cluster)
library(HSAUR)
library(fpc)
library(corrplot)


combined_corr <- cor(combined_clustering_matrix,use = "complete.obs")   # NA are removed

# Kmeans clustre analysis
res_clustering <- kmeans(combined_clustering_matrix, centers = 10)
summary(res_clustering)

col<- colorRampPalette(c("blue", "white", "red"))(20)
heatmap(x = combined_corr, col = col, symm = TRUE)
```




biorepliation same animal 
bioreps -strains 
single metabolites that is good

Add indexes for replicaites using the mod function on the sample index
```{r}
Technical_rep_1 <- filter(metab_data,replicate == "rep_1")

Index <- Technical_rep_1$Index
Match_strings <- paste(Technical_rep_1$Strain,Technical_rep_1$Age,sep = ",")


Duplicate_indicies <- sort(unique(
                      c(which(duplicated(Match_strings)),
                        which(duplicated(Match_strings,fromLast = TRUE)))))

Bioreplicate_vector <- rep.int(0, nrow(Technical_rep_1)) 
Bioreplicate_vector[Duplicate_indicies] <- 1

Bioreplicate_df <- cbind.data.frame(Index,Match_strings,Bioreplicate_vector)
Bioreplicate_df <- Bioreplicate_df[with(Bioreplicate_df, order(Match_strings)), ]

x <- inner_join(Bioreplicate_df,Technical_rep_1)

paste(Bioreplicate_df$Bioreplicate_vector,collapse = ",")

#zou need to have unqiue values in the bz mere
#can be done by selecting multiple columns
```


Prior to clustering data, remove or estimate missing data and rescale variables for comparability.
```{r}
clustering_dataset <- data[, - c(2,3,4,5,8,11)]
clustering_matrix <- clustering_dataset[1:25,-c(1:7)]
numeric_clustering_matrix <- matrix(as.numeric(unlist(clustering_matrix)),nrow=nrow(clustering_matrix))
```

Prepare Data for Clustering Analysis
```{r}
mydata <- na.omit(numeric_clustering_matrix) # listwise deletion of missing
any(is.na(mydata)) #Check any NAs
mydata <- scale(numeric_clustering_matrix) # standardize variables
```

K-means clustering partitioning Method 
This requires number of clusters to extract. 
A plot of the within groups sum of squares by number of clusters extracted can help determine the appropriate number of clusters. 
```{r}
# Determine number of clusters
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(mydata, 
  	centers=i)$withinss)

plot(1:15, wss, type="b", xlab="Number of Clusters",
  ylab="Within groups sum of squares")
```


```{r}
# K-Means Cluster Analysis
fit_kmeans <- kmeans(mydata, 5) # 5 cluster solution
# get cluster means 
aggregate(mydata,by=list(fit_kmeans$cluster),FUN=mean)
# append cluster assignment
mydata <- data.frame(mydata, fit$cluster)
```

Hierarchical Agglomerative
```{r}
# Ward Hierarchical Clustering
d <- dist(mydata, method = "euclidean") # distance matrix
fit <- hclust(d, method="ward") 
plot(fit) # display dendogram
groups <- cutree(fit, k=5) # cut tree into 5 clusters
# draw dendogram with red borders around the 5 clusters 
rect.hclust(fit, k=5, border="red")
```


The pvclust( ) function in the pvclust package provides p-values for hierarchical clustering based on multiscale bootstrap resampling. Clusters that are highly supported by the data will have large p values. 
Pvclust clusters columns, not rows. Data needs to be tarnsposed before using

```{r}
# Ward Hierarchical Clustering with Bootstrapped p values
library(pvclust)
fit_ward <- pvclust(mydata, method.hclust="ward",
   method.dist="euclidean",nboot = 10)
plot(fit) # dendogram with p values
# add rectangles around groups highly supported by the data
pvrect(fit, alpha=.95)
```

Model based approaches assume a variety of data models and apply maximum likelihood estimation and Bayes criteria to identify the most likely model and number of clusters. Specifically, the Mclust( ) function in the mclust package selects the optimal model according to BIC for EM initialized by hierarchical clustering for parameterized Gaussian mixture models. One chooses the model and number of clusters with the largest BIC.help(mclustModelNames) to details on the model chosen as best.

```{r}
# Model Based Clustering
library(mclust)
fit <- Mclust(mydata)
plot(fit) # plot results 
summary(fit) # display the best model
```

Plotting Cluster Solutions
It is always a good idea to look at the cluster results.

```{r}
# K-Means Clustering with 5 clusters
fit <- kmeans(mydata, 5)

# Cluster Plot against 1st 2 principal components

# vary parameters for most readable graph
library(cluster) 


clusplot(mydata2, fit$cluster, color=TRUE, shade=TRUE, 
  	labels=2, lines=0)

# Centroid Plot against 1st 2 discriminant functions
library(fpc)
plotcluster(mydata2, fit$cluster)
```

The function cluster.stats() in the fpc package provides a mechanism for comparing the similarity of two cluster solutions using a variety of validation criteria (Hubert's gamma coefficient, the Dunn index and the corrected rand index)
```{r}
# comparing 2 cluster solutions
library(fpc)
cluster.stats(d, fit_kmeans$cluster, fit_ward$cluster)
```



